Publication Type,Authors,Article Title,Source Title,Publication Year,Author Keywords,Abstract,Research Areas,Open Access,Satellite,Application,Domain,ML Technique,Algorithm Complexity,Accuracy (%),F1-score (%),Precision (%),Recall (%),Producer accuracy (%),User accuracy (%),Pixel accuracy,Kappa (%),IoU (%),MIoU (%),Dice (%),R-squared,RMSE,MAE,Parameter Description
J,"Salah, Muhammad; Higa, Hiroto; Ishizaka, Joji; Salem, Salem Ibrahim",1D Convolutional Neural Network-based Chlorophyll-a Retrieval Algorithm for Sentinel-2 MultiSpectral Instrument in Various Trophic States,SENSORS AND MATERIALS,2023,chlorophyll-a; Sentinel-2; MultiSpectral Instrument; deep learning; convolutional neural network; ocean color,"Despite extensive research on chlorophyll-a (Chla) concentration retrieval methods from remote sensing reflectance (Rrs, sr(-1)) data, there remains a need for more reliable Chla retrieval techniques. In this study, we introduce a deep learning approach based on a 1D convolutional neural network (1D CNN) architecture. In addition, we provide a new method of representing the Rrs as a sequential vector. The model architecture targets the Sentinel-2 MultiSpectral Instrument (MSI) sensor. The proposed model was trained and tested on simulated and in situ data collected from broad trophic states in Japan and Vietnam waters with Chla concentrations ranging from 0.02 to 148.26 mg/m(3). The proposed model was evaluated against well-accepted state-of-the-art methods: ocean color three-band (OC3), ocean color index (OCI), two-band ratio, Blend, and a neural network model with a mixture density network. The evaluation shows that the proposed method outperforms other methods with a 7.48-38.02% reduction in root mean squared error (RMSE) and an 11.50-39.17% lower mean absolute error (MAE) than the other methods. The promising performance of the proposed model suggests that more attention should be paid to the domain of sequence modeling for Rrs and the architecture of 1D CNN.",Instruments & Instrumentation; Materials Science,yes,Sentinel-2,Estimating ocean surface chlorophyll-a,Water,Regression,no,,,,,,,,,,,,,4.12,1.06,Chl-a (mg/m3)
J,"Fathi, Mahdiyeh; Shah-Hosseini, Reza; Moghimi, Armin","3D-ResNet-BiLSTM Model: A Deep Learning Model for County-Level Soybean Yield Prediction with Time-Series Sentinel-1, Sentinel-2 Imagery, and Daymet Data",REMOTE SENSING,2023,soybean; yield prediction; Conv3D; ResNet; BiLSTM; Sentinel 1-2; Daymet; Google Earth Engine (GEE),"Ensuring food security in precision agriculture requires early prediction of soybean yield at various scales within the United States (U.S.), ranging from international to local levels. Accurate yield estimation is essential in preventing famine by providing insights into food availability during the growth season. Numerous deep learning (DL) algorithms have been developed to estimate soybean yield effectively using time-series remote sensing (RS) data to achieve this goal. However, the training data with short time spans can limit their ability to adapt to the dynamic and nuanced temporal changes in crop conditions. To address this challenge, we designed a 3D-ResNet-BiLSTM model to efficiently predict soybean yield at the county level across the U.S., even when using training data with shorter periods. We leveraged detailed Sentinel-2 imagery and Sentinel-1 SAR images to extract spectral bands, key vegetation indices (VIs), and VV and VH polarizations. Additionally, Daymet data was incorporated via Google Earth Engine (GEE) to enhance the model's input features. To process these inputs effectively, a dedicated 3D-ResNet architecture was designed to extract high-level features. These enriched features were then fed into a BiLSTM layer, enabling accurate prediction of soybean yield. To evaluate the efficacy of our model, its performance was compared with that of well-known models, including the Linear Regression (LR), Random Forest (RF), and 1D/2D/3D-ResNet models, as well as a 2D-CNN-LSTM model. The data from a short period (2019 to 2020) were used to train all models, while their accuracy was assessed using data from the year 2021. The experimental results showed that the proposed 3D-Resnet-BiLSTM model had a superior performance compared to the other models, achieving remarkable metrics (R2 = 0.791, RMSE = 5.56 Bu Ac-1, MAE = 4.35 Bu Ac-1, MAPE = 9%, and RRMSE = 10.49%). Furthermore, the 3D-ResNet-BiLSTM model showed a 7% higher R2 than the ResNet and RF models and an enhancement of 27% and 17% against the LR and 2D-CNN-LSTM models, respectively. The results highlighted our model's potential for accurate soybean yield predictions, supporting sustainable agriculture and food security.",Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology,yes,Sentinel-2,Predicting soybean yield,Vegetation,Regression,yes,,,,,,,,,,,,0.745,6.085,4.895,Soybean yield (Bu Ac−1)
J,"Rawat, A; Kumar, A; Upadhyay, P; Kumar, S",A Comparative Study of 1D-Convolutional Neural Networks with Modified Possibilistic c-Mean Algorithm for Mapping Transplanted Paddy Fields Using Temporal Data,JOURNAL OF THE INDIAN SOCIETY OF REMOTE SENSING,2022,Image classification; Temporal; 1D-CNN; MPCM; Fuzzy-based algorithm; Learning-based algorithm,"With increasing availability of satellite data of high temporal resolution, a more robust classifier is needed which can exploit the temporal information along with the spectral information of the remote sensing images. Specific fuzzy-based and learning-based algorithms are two broad categories and have the potential to perform well in spectral-temporal domain. In the present study, for mapping paddy fields as a specific class two classification algorithms, viz. fuzzy-based modified possibilistic c-mean (MPCM) algorithm and learning-based 1D-convolutional neural networks (CNN), were tested using Sentinel-2A/2B temporal data. The overall accuracy for learning-based 1D-CNN and fuzzy-based MPCM classifiers was found to be 96% and 93%, respectively. The F-measure values were found to be 0.95 and 0.92 for 1D-CNN- and MPCM-based classifier, respectively. Thus, it can be inferred from this study that the 1D-CNN classifier performed better than the traditional fuzzy-based classifier and can handle heterogeneity within class.",Environmental Sciences & Ecology; Remote Sensing,no,Sentinel-2,Mapping Transplanted Paddy Fields,Vegetation,Classification,no,96,95,,,,,,,,,,,,,
J,"Zhou, Xuewen; Xin, Qinchuan; Dai, Yongjiu; Li, Wanjing",A deep-learning-based experiment for benchmarking the performance of global terrestrial vegetation phenology models,GLOBAL ECOLOGY AND BIOGEOGRAPHY,2021,convolutional neural network; land surface process; phenology metrics; remote sensing; vegetation phenology modelling,"Aim Vegetation phenology that characters the periodic life cycles of plants is indicative of the interactions between the biosphere and the atmosphere. Robust modelling of vegetation phenology metrics that correspond to canopy development events is essential to our understanding of how plants and ecosystems respond to a changing climate. Given considerable uncertainties associated with vegetation phenology modelling using numerical models, we explore the deep learning approach to predicting the timing of global vegetation phenology metrics. Location Global. Time period 2001-2015. Major taxa studied Deciduous vegetation (DV), stressed deciduous vegetation (SDV), evergreen vegetation (EV). Methods We developed a one-dimensional convolutional neural network regression (1D-CNNR) model with 10 hierarchical structures to model global vegetation phenology using meteorological variables as inputs. The developed deep learning model was evaluated using satellite-derived phenology metrics (i.e., green-up, maturity, senescence, and dormancy) and compared with the terrestrial ecosystem model Biome-BGC (BioGeochemical Cycles). Results Our experimental results show that the 1D-CNNR model well captures both the spatial pattern and inter-annual variation of satellite-derived multiyear vegetation phenology metrics on a global scale. The median root-mean-square errors (RMSEs) and standard deviations between phenology metrics derived from the Moderate Resolution Imaging Spectroradiometer (MODIS) data and predicted by the 1D-CNNR model on a global scale from 2001 to 2015 are 4.1 +/- 5.9, 4.2 +/- 12.1, 3.0 +/- 6.8, and 3.4 +/- 4.3 days for green-up, maturation, senescence, and dormancy, respectively, for the DV type; 13.3 +/- 29.6, 8.4 +/- 29.1, 8.1 +/- 21.3, and 9.1 +/- 21.6 days for green-up, maturation, senescence, and dormancy, respectively, for the SDV type; and 13.9 +/- 17.4, 17.7 +/- 34.6, 18.8 +/- 42.9, and 12.1 +/- 17.7 days for green-up, maturation, senescence, and dormancy, respectively, for the EV type. Main conclusions This research demonstrates that the 1D-CNNR model has the potential for large-scale modelling of vegetation phenology. Results from the deep learning model suggest that there is room to improve numerical vegetation phenology models for use in land surface models.",Environmental Sciences & Ecology; Physical Geography,no,MODIS,Global vegetation phenology,Vegetation,Regression,yes,,,,,,,,,,,,,,,
J,"Zeng, You; Liang, Tianlong; Fan, Donglin; He, Hongchang",A Novel Algorithm for the Retrieval of Chlorophyll a in Marine Environments Using Deep Learning,WATER,2023,marine; chlorophyll a; remote sensing inversion; deep learning,"Chlorophyll a (Chla) is a crucial pigment in phytoplankton, playing a vital role in determining phytoplankton biomass and water nutrient status. However, in optically complex water bodies, Chla concentration is no longer the primary factor influencing remote sensing spectral reflectance signals, leading to significant errors in traditional Chla concentration estimation methods. With advancements in in situ measurements, synchronized satellite data, and computer technology, machine learning algorithms have become popular in Chla concentration retrieval. Nevertheless, when using machine learning methods to estimate Chla concentration, abrupt changes in Chla values can disrupt the spatiotemporal smoothness of the retrieval results. Therefore, this study proposes a two-stage approach to enhance the accuracy of Chla concentration estimation in optically complex water bodies. In the first stage, a one-dimensional convolutional neural network (1D CNN) is employed for precise Chla retrieval, and in the second stage, the regression layer of the 1DCNN is replaced with support vector regression (SVR). The research findings are as follows: (1) In the first stage, the performance metrics (R2, RMSE, RMLSE, Bias, MAE) of the 1D CNN outperform state-of-the-art algorithms (OCI, SVR, RFR) on the test dataset. (2) After the second stage, the performance further improves, with the metrics achieving values of 0.892, 11.243, 0.052, 1.056, and 1.444, respectively. (3) In mid- to high-latitude regions, the inversion performance of 1D CNN\SVR is superior to other algorithms, exhibiting richer details and higher noise tolerance in nearshore areas. (4) 1D CNN\SVR demonstrates high inversion capabilities in water bodies with medium-to-high nutrient levels.",Environmental Sciences & Ecology; Water Resources,yes,MODIS,Retrieval of Chlorophyll a in Marine Environments,Water,Regression,no,,,,,,,,,,,,0.874,18.968,1.494,Chl-a (mg/m3)
J,"Ivanda, Antonia; Seric, Ljiljana; Zagar, Dusan; Ostir, Kristof",An application of 1D convolution and deep learning to remote sensing modelling of Secchi depth in the northern Adriatic Sea,BIG EARTH DATA,2023,Secchi; Sentinel-3; OLCI; 1D-CNN; Adriatic sea,"This paper presents a novel approach for predicting the water quality indicator - Secchi disk depth (ZSD). ZSD indirectly reflects water clarity and serves as a proxy for other quality parameters. This study utilizes Deep Neural Network (DNN) trained on satellite remote sensing and measured data from three sources: two datasets obtained from official agencies in Croatia and Slovenia, and one citizen science data source, all covering the northern coastal region of the Adriatic Sea. The proposed model uses 1D Convolutional Neural Network (CNN) in the spectral dimension to predict ZSD. The model's performance indicates a strong fit to the observed data, proving capability of 1D-CNN to capture changes in water transparency. On the test dataset, the model achieved a high R-squared value of 0.890, a low root mean squared error (RMSE) of 0.023 and mean absolute error (MAE) of 0.014. These results demonstrate that employing a 1D-CNN in the spectral dimension of Sentinel-3 OLCI data is an effective approach for predicting water quality. These findings have significant implications for monitoring ZSD in coastal areas. By integrating diverse data sources and leveraging advanced machine learning algorithms, a more accurate and comprehensive assessment of water quality can be achieved.",Computer Science; Geology; Remote Sensing,yes,Sentinel-3,Predicting secchi disk depth,Water,Regression,no,,,,,,,,,,,,0.89,2.3,1.4,Meter (m)
J,"Ma, Ye; Zhen, Zhen; Li, Fengri; Feng, Fujuan; Zhao, Yinghui","An innovative lightweight 1D-CNN model for efficient monitoring of large-scale forest composition: a case study of Heilongjiang Province, China",GISCIENCE & REMOTE SENSING,2023,1D-CNN; SEM; large-scale mapping; forest composition change monitoring; Landsat,"Large-scale forest composition mapping and change monitoring are essential for regional and national forest resource management, monitoring, and carbon stock assessment. However, the existing large-scale mapping methods are not effective enough in terms of efficiency and accuracy. To address this limitation, this study proposes a lightweight one-dimensional convolutional neural network (LW-CNN) model for forest composition mapping. The LW-CNN model is developed using Landsat imagery covering 470,700 km2 obtained from Google Earth Engine (GEE) collected during two periods (2007 and 2018). The proposed LW-CNN is compared with a visual geometry group with 16 convolutional layers (VGG16), a residual network with 34 convolutional layers (Resnet34), and a residual network with 50 convolutional layers (Resnet50) in terms of model accuracy and efficiency. The factors influencing forest composition change are analyzed using the structural equation model (SEM). The results show that the proposed LW-CNN model can outperform the other three models in terms of model accuracy, achieving a mean overall accuracy (OA) of: 0.75 and efficiency of 7-22-fold. The changed forest composition from 2007 to 2018 accounts for 29.6% of the total forest area. The SEM results show that the climate factors have the most significant effect on the forest composition change. This study presents an innovative model for large-scale forest composition mapping, which is proven to be both efficient and accurate. This study also provides insights into the factors that affect the forest composition change, which could be valuable for forest resource management, monitoring, and carbon stock assessment.",Physical Geography; Remote Sensing,yes,Landsat-8,Forest composition,Vegetation,Classification,yes,75,,,,,,,,,,,,,,
C,Cordova K.M.N.; Sritarapipat T.; Piyatadsananon P.,APPLICATION of CNN on LANDSLIDE SUSCEPTIBILITY ANALYSIS: CASE STUDY on 2018 HOKKAIDO EASTERN IBURI EARTHQUAKE,"42nd Asian Conference on Remote Sensing, ACRS 2021",2021,convolutional neural network; deep learning; landslides,"Landslides are one of the most common geohazards occurring worldwide. Landslide susceptibility mapping is crucial to vulnerable areas in terms of mitigating the future impacts from this reoccurrence. Landslide susceptibility mapping has been generated for a long time with standard methods such as fuzzy logic, analytical hierarchy process (AHP), and logistic regression. Recently, conventional machine learning algorithms have been considered as an advanced technique for landslide susceptibility mapping. In addition, it is possible to use artificial neural networks and deep learning models in place of conventional machine learning algorithms to provide significant results. This study proposes a deep 1-dimensional convolutional neural network (CNN-1D) model to predict landslides and evaluate its performance on landslide susceptibility mapping. The proposed model was applied to Hokkaido prefecture, where 4,350 landslide scars have been extracted and identified from satellite images dated shortly after the 2018 Hokkaido Eastern Iburi earthquake. As a result, the CNN-1D model provides 96% accuracy, with 97% precision on the landslide class with 94% recall. In conclusion, applying the deep learning technique (CNN- 1D model) can yield a significantly accurate landslide susceptibility map. © ACRS 2021.All right reserved.",,yes,Sentinel-2,Landslide susceptibility analysis,Geohazards,Classification,no,96,96,97,94,,,,,,,,,,,
J,"Tsangaratos, Paraskevas; Ilia, Ioanna; Chrysafi, Aikaterini-Alexandra; Matiatos, Ioannis; Chen, Wei; Hong, Haoyuan","Applying a 1D Convolutional Neural Network in Flood Susceptibility Assessments-The Case of the Island of Euboea, Greece",REMOTE SENSING,2023,flood susceptibility; remote sensing; convolutional neural network; geoinformatics; Euboea; Greece,"The main scope of the study is to evaluate the prognostic accuracy of a one-dimensional convolutional neural network model (1D-CNN), in flood susceptibility assessment, in a selected test site on the island of Euboea, Greece. Logistic regression (LR), Naive Bayes (NB), gradient boosting (GB), and a deep learning neural network (DLNN) model are the benchmark models used to compare their performance with that of a 1D-CNN model. Remote sensing (RS) techniques are used to collect the necessary flood related data, whereas thirteen flash-flood-related variables were used as predictive variables, such as elevation, slope, plan curvature, profile curvature, topographic wetness index, lithology, silt content, sand content, clay content, distance to faults, and distance to river network. The Weight of Evidence method was applied to calculate the correlation among the flood-related variables and to assign a weight value to each variable class. Regression analysis and multi-collinearity analysis were used to assess collinearity among the flood-related variables, whereas the Shapley Additive explanations method was used to rank the features by importance. The evaluation process involved estimating the predictive ability of all models via classification accuracy, sensitivity, specificity, and area under the success and predictive rate curves (AUC). The outcomes of the analysis confirmed that the 1D-CNN provided a higher accuracy (0.924), followed by LR (0.904) and DLNN (0.899). Overall, 1D-CNNs can be useful tools for analyzing flood susceptibility using remote sensing data, with high accuracy predictions.",Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology,yes,Sentinel-2,Flood Susceptibility Assessments,Geohazards,Classification,no,,,,,,,,,,,,,,,
C,M. Salah; H. Higa; J. Ishizaka; S. I. Salem,B1D-CNN: A Novel Convolution Neural Network-Based Chlorophyll-A Retrieval Algorithm for Sentinel-2 Data,IGARSS 2023 - 2023 IEEE International Geoscience and Remote Sensing Symposium,2023,Chlorophyll-a;CNN;MSI;Ocean Color,"Deep learning (DL) methods have been recently considered suitable for Chlorophyll-a (Chla) retrieval from satellite data due to their ability for handling complex, high-dimensional, and noisy data. This manuscript describes B1Dâ€“CNN, a new model combining 1D-convolutional neural networks (1D-CNN) and a traditional empirical blend algorithm to estimate Chla using the MultiSpectral Instrument (MSI) sensor on board the Sentinel-2 satellite. The proposed model is trained and evaluated against the state-of-the-art Mixture Density Network (MDN) and the classical Chla retrieval algorithms using global in-situ data. The results show a 9.25% to 54.12% improvement in the RMSE, along with a 3.45% to 59.53% reduction in the MAE. A satellite image during a harmful algal bloom (HABs) event was also assessed using B1Dâ€“CNN, and the proposed model captured the high Chla batches associated with HABs. This study indicates the advantages of using DL methods to retrieve Chla.",Deep learning;Satellites;Image color analysis;Instruments;Neural networks;Geoscience and remote sensing;Data models,yes,Sentinel-2,Estimating chlorophyll-a Concentration,Water,Regression,yes,,,,,,,,,,,,,11.87,6.71,Chl-a (mg/m3)
J,"Fan, DL; He, HC; Wang, RS; Zeng, Y; Fu, BL; Xiong, YK; Liu, LL; Xu, Y; Gao, ET",CHLNET: A novel hybrid 1D CNN-SVR algorithm for estimating ocean surface chlorophyll-a,FRONTIERS IN MARINE SCIENCE,2022,chlorophyll-a inversion; hybrid algorithm; one-dimensional convolution neural network; feature extraction; ocean color; cross-water types,"Developing a unified chlorophyll-a (Chla) inversion algorithm for cross-water types is a significant challenge owing to the insufficiency of input features and training samples. Although machine learning algorithms can build a consistent model for different trophic waters, the accuracy of the inversion is dependent on the quality of the extended features. Here, we designed a novel hybrid framework called CHLNET, which combines a one-dimensional convolutional neural network (1D CNN) and support vector regression (SVR). The 1D CNN is used to extract features from the original band features, and the SVR is used to perform a fit of Chla. CHLNET is trained and tested using match-up pairs of SeaWiFS remote sensing reflectance [Rrs(lambda)] in situ with Chla ranging from 0.009 mg/m(3) to 138.046 mg/m(3), which covers mostly ocean water types. Performance metrics in the log space of CHLNET were better than those of the state-of-the-art algorithms on the testing dataset, and CHLNET had the best overall performance with the largest cover area in the star plot. The frequency distribution of predicted Chla by CHLNET was more consistent with that of in situ Chla. While the spatial pattern was not smooth in low Chla concentration waters, CHLNET demonstrated excellent mapping ability at the global and local scales in high Chla concentration waters. Through the band-shift method, which transfers the Rrs(lambda) of MERIS and MODIS-Aqua to the Rrs(lambda) of SeaWiFS in the visible spectral range, CHLNET obtained better accuracy than the blended algorithm of OCx and CI on MERIS and MODIS-Aqua matchups, which validates the generalization of CHLNET on cross-sensor types. The results indicate that CHLNET avoids the drawbacks of manually constructing extended features and the need for merging water type-appropriate algorithms for Chla retrieval, as well as provides a new idea for unified Chla concentration inversion across water types. Thus, CHLNET may serve as an alternative approach for Chla inversion.",Environmental Sciences & Ecology; Marine & Freshwater Biology,yes,SeaWiFS,Estimating ocean surface chlorophyll-a,Water,Regression,no,,,,,,,,,,,,0.874,"8,178","1,487",Chl-a (mg/m3)
J,"Fan, DL; He, HC; Wang, RS; Zeng, Y; Fu, BL; Xiong, YK; Liu, LL; Xu, Y; Gao, ET",CHLNET: A novel hybrid 1D CNN-SVR algorithm for estimating ocean surface chlorophyll-a,FRONTIERS IN MARINE SCIENCE,2022,chlorophyll-a inversion; hybrid algorithm; one-dimensional convolution neural network; feature extraction; ocean color; cross-water types,"Developing a unified chlorophyll-a (Chla) inversion algorithm for cross-water types is a significant challenge owing to the insufficiency of input features and training samples. Although machine learning algorithms can build a consistent model for different trophic waters, the accuracy of the inversion is dependent on the quality of the extended features. Here, we designed a novel hybrid framework called CHLNET, which combines a one-dimensional convolutional neural network (1D CNN) and support vector regression (SVR). The 1D CNN is used to extract features from the original band features, and the SVR is used to perform a fit of Chla. CHLNET is trained and tested using match-up pairs of SeaWiFS remote sensing reflectance [Rrs(lambda)] in situ with Chla ranging from 0.009 mg/m(3) to 138.046 mg/m(3), which covers mostly ocean water types. Performance metrics in the log space of CHLNET were better than those of the state-of-the-art algorithms on the testing dataset, and CHLNET had the best overall performance with the largest cover area in the star plot. The frequency distribution of predicted Chla by CHLNET was more consistent with that of in situ Chla. While the spatial pattern was not smooth in low Chla concentration waters, CHLNET demonstrated excellent mapping ability at the global and local scales in high Chla concentration waters. Through the band-shift method, which transfers the Rrs(lambda) of MERIS and MODIS-Aqua to the Rrs(lambda) of SeaWiFS in the visible spectral range, CHLNET obtained better accuracy than the blended algorithm of OCx and CI on MERIS and MODIS-Aqua matchups, which validates the generalization of CHLNET on cross-sensor types. The results indicate that CHLNET avoids the drawbacks of manually constructing extended features and the need for merging water type-appropriate algorithms for Chla retrieval, as well as provides a new idea for unified Chla concentration inversion across water types. Thus, CHLNET may serve as an alternative approach for Chla inversion.",Environmental Sciences & Ecology; Marine & Freshwater Biology,yes,MERIS,Estimating ocean surface chlorophyll-a,Water,Regression,no,,,,,,,,,,,,0.915,"12,523","1,465",Chl-a (mg/m3)
J,"Fan, DL; He, HC; Wang, RS; Zeng, Y; Fu, BL; Xiong, YK; Liu, LL; Xu, Y; Gao, ET",CHLNET: A novel hybrid 1D CNN-SVR algorithm for estimating ocean surface chlorophyll-a,FRONTIERS IN MARINE SCIENCE,2022,chlorophyll-a inversion; hybrid algorithm; one-dimensional convolution neural network; feature extraction; ocean color; cross-water types,"Developing a unified chlorophyll-a (Chla) inversion algorithm for cross-water types is a significant challenge owing to the insufficiency of input features and training samples. Although machine learning algorithms can build a consistent model for different trophic waters, the accuracy of the inversion is dependent on the quality of the extended features. Here, we designed a novel hybrid framework called CHLNET, which combines a one-dimensional convolutional neural network (1D CNN) and support vector regression (SVR). The 1D CNN is used to extract features from the original band features, and the SVR is used to perform a fit of Chla. CHLNET is trained and tested using match-up pairs of SeaWiFS remote sensing reflectance [Rrs(lambda)] in situ with Chla ranging from 0.009 mg/m(3) to 138.046 mg/m(3), which covers mostly ocean water types. Performance metrics in the log space of CHLNET were better than those of the state-of-the-art algorithms on the testing dataset, and CHLNET had the best overall performance with the largest cover area in the star plot. The frequency distribution of predicted Chla by CHLNET was more consistent with that of in situ Chla. While the spatial pattern was not smooth in low Chla concentration waters, CHLNET demonstrated excellent mapping ability at the global and local scales in high Chla concentration waters. Through the band-shift method, which transfers the Rrs(lambda) of MERIS and MODIS-Aqua to the Rrs(lambda) of SeaWiFS in the visible spectral range, CHLNET obtained better accuracy than the blended algorithm of OCx and CI on MERIS and MODIS-Aqua matchups, which validates the generalization of CHLNET on cross-sensor types. The results indicate that CHLNET avoids the drawbacks of manually constructing extended features and the need for merging water type-appropriate algorithms for Chla retrieval, as well as provides a new idea for unified Chla concentration inversion across water types. Thus, CHLNET may serve as an alternative approach for Chla inversion.",Environmental Sciences & Ecology; Marine & Freshwater Biology,yes,MODIS,Estimating ocean surface chlorophyll-a,Water,Regression,no,,,,,,,,,,,,0.894,"6,727","1,448",Chl-a (mg/m3)
J,"Ma, N; Sun, L; Zhou, CH; He, YW",Cloud Detection Algorithm for Multi-Satellite Remote Sensing Imagery Based on a Spectral Library and 1D Convolutional Neural Network,REMOTE SENSING,2021,ASTER spectral library; hyperspectral data; 1D convolutional neural network; cloud detection; data simulation; multi-satellite remote sensing images,"Automatic cloud detection in remote sensing images is of great significance. Deep-learning-based methods can achieve cloud detection with high accuracy; however, network training heavily relies on a large number of labels. Manually labelling pixel-wise level cloud and non-cloud annotations for many remote sensing images is laborious and requires expert-level knowledge. Different types of satellite images cannot share a set of training data, due to the difference in spectral range and spatial resolution between them. Hence, labelled samples in each upcoming satellite image are required to train a new deep-learning-based model. In order to overcome such a limitation, a novel cloud detection algorithm based on a spectral library and convolutional neural network (CD-SLCNN) was proposed in this paper. In this method, the residual learning and one-dimensional CNN (Res-1D-CNN) was used to accurately capture the spectral information of the pixels based on the prior spectral library, effectively preventing errors due to the uncertainties in thin clouds, broken clouds, and clear-sky pixels during remote sensing interpretation. Benefiting from data simulation, the method is suitable for the cloud detection of different types of multispectral data. A total of 62 Landsat-8 Operational Land Imagers (OLI), 25 Moderate Resolution Imaging Spectroradiometers (MODIS), and 20 Sentinel-2 satellite images acquired at different times and over different types of underlying surfaces, such as a high vegetation coverage, urban area, bare soil, water, and mountains, were used for cloud detection validation and quantitative analysis, and the cloud detection results were compared with the results from the function of the mask, MODIS cloud mask, support vector machine, and random forest. The comparison revealed that the CD-SLCNN method achieved the best performance, with a higher overall accuracy (95.6%, 95.36%, 94.27%) and mean intersection over union (77.82%, 77.94%, 77.23%) on the Landsat-8 OLI, MODIS, and Sentinel-2 data, respectively. The CD-SLCNN algorithm produced consistent results with a more accurate cloud contour on thick, thin, and broken clouds over a diverse underlying surface, and had a stable performance regarding bright surfaces, such as buildings, ice, and snow.",Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology,yes,Landsat-8,Cloud Detection,Others,Classification,yes,95,,,,83.21,96.21,,84.27,,77.82,,,,,
J,"Ma, N; Sun, L; Zhou, CH; He, YW",Cloud Detection Algorithm for Multi-Satellite Remote Sensing Imagery Based on a Spectral Library and 1D Convolutional Neural Network,REMOTE SENSING,2021,ASTER spectral library; hyperspectral data; 1D convolutional neural network; cloud detection; data simulation; multi-satellite remote sensing images,"Automatic cloud detection in remote sensing images is of great significance. Deep-learning-based methods can achieve cloud detection with high accuracy; however, network training heavily relies on a large number of labels. Manually labelling pixel-wise level cloud and non-cloud annotations for many remote sensing images is laborious and requires expert-level knowledge. Different types of satellite images cannot share a set of training data, due to the difference in spectral range and spatial resolution between them. Hence, labelled samples in each upcoming satellite image are required to train a new deep-learning-based model. In order to overcome such a limitation, a novel cloud detection algorithm based on a spectral library and convolutional neural network (CD-SLCNN) was proposed in this paper. In this method, the residual learning and one-dimensional CNN (Res-1D-CNN) was used to accurately capture the spectral information of the pixels based on the prior spectral library, effectively preventing errors due to the uncertainties in thin clouds, broken clouds, and clear-sky pixels during remote sensing interpretation. Benefiting from data simulation, the method is suitable for the cloud detection of different types of multispectral data. A total of 62 Landsat-8 Operational Land Imagers (OLI), 25 Moderate Resolution Imaging Spectroradiometers (MODIS), and 20 Sentinel-2 satellite images acquired at different times and over different types of underlying surfaces, such as a high vegetation coverage, urban area, bare soil, water, and mountains, were used for cloud detection validation and quantitative analysis, and the cloud detection results were compared with the results from the function of the mask, MODIS cloud mask, support vector machine, and random forest. The comparison revealed that the CD-SLCNN method achieved the best performance, with a higher overall accuracy (95.6%, 95.36%, 94.27%) and mean intersection over union (77.82%, 77.94%, 77.23%) on the Landsat-8 OLI, MODIS, and Sentinel-2 data, respectively. The CD-SLCNN algorithm produced consistent results with a more accurate cloud contour on thick, thin, and broken clouds over a diverse underlying surface, and had a stable performance regarding bright surfaces, such as buildings, ice, and snow.",Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology,yes,MODIS,Cloud Detection,Others,Classification,yes,95.36,,,,92.16,98.74,,83.78,,77.94,,,,,
J,"Ma, N; Sun, L; Zhou, CH; He, YW",Cloud Detection Algorithm for Multi-Satellite Remote Sensing Imagery Based on a Spectral Library and 1D Convolutional Neural Network,REMOTE SENSING,2021,ASTER spectral library; hyperspectral data; 1D convolutional neural network; cloud detection; data simulation; multi-satellite remote sensing images,"Automatic cloud detection in remote sensing images is of great significance. Deep-learning-based methods can achieve cloud detection with high accuracy; however, network training heavily relies on a large number of labels. Manually labelling pixel-wise level cloud and non-cloud annotations for many remote sensing images is laborious and requires expert-level knowledge. Different types of satellite images cannot share a set of training data, due to the difference in spectral range and spatial resolution between them. Hence, labelled samples in each upcoming satellite image are required to train a new deep-learning-based model. In order to overcome such a limitation, a novel cloud detection algorithm based on a spectral library and convolutional neural network (CD-SLCNN) was proposed in this paper. In this method, the residual learning and one-dimensional CNN (Res-1D-CNN) was used to accurately capture the spectral information of the pixels based on the prior spectral library, effectively preventing errors due to the uncertainties in thin clouds, broken clouds, and clear-sky pixels during remote sensing interpretation. Benefiting from data simulation, the method is suitable for the cloud detection of different types of multispectral data. A total of 62 Landsat-8 Operational Land Imagers (OLI), 25 Moderate Resolution Imaging Spectroradiometers (MODIS), and 20 Sentinel-2 satellite images acquired at different times and over different types of underlying surfaces, such as a high vegetation coverage, urban area, bare soil, water, and mountains, were used for cloud detection validation and quantitative analysis, and the cloud detection results were compared with the results from the function of the mask, MODIS cloud mask, support vector machine, and random forest. The comparison revealed that the CD-SLCNN method achieved the best performance, with a higher overall accuracy (95.6%, 95.36%, 94.27%) and mean intersection over union (77.82%, 77.94%, 77.23%) on the Landsat-8 OLI, MODIS, and Sentinel-2 data, respectively. The CD-SLCNN algorithm produced consistent results with a more accurate cloud contour on thick, thin, and broken clouds over a diverse underlying surface, and had a stable performance regarding bright surfaces, such as buildings, ice, and snow.",Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology,yes,Sentinel-2,Cloud Detection,Others,Classification,yes,94.27,,,,91.61,96.84,,81.17,,77.23,,,,,
J,"Moncrieff, GR",Continuous Land Cover Change Detection in a Critically Endangered Shrubland Ecosystem Using Neural Networks,REMOTE SENSING,2022,land cover change; land cover monitoring; deep learning; Renosterveld; threatened ecosystems; Sentinel 2; planet labs,"Existing efforts to continuously monitor land cover change using satellite image time series have mostly focused on forested ecosystems in the tropics and the Northern Hemisphere. The notable difference in spectral reflectance that occurs following deforestation allows land cover change to be detected with relative accuracy. Less progress has been made in detecting change in low productivity or disturbance-prone vegetation such as grasslands and shrublands where natural dynamics can be difficult to distinguish from habitat loss. Renosterveld is a hyperdiverse, critically endangered shrubland ecosystem in South Africa with less than 5-10% of its original extent remaining in small, highly fragmented patches. I demonstrate that classification of satellite image time series using neural networks can accurately detect the transformation of Renosterveld within a few days of its occurrence and that trained models are suitable for operational continuous monitoring. A dataset of precisely dated vegetation change events between 2016 and 2021 was obtained from daily, high resolution Planet Labs satellite data. This dataset was then used to train 1D convolutional neural networks and Transformers to continuously detect land cover change events in time series of vegetation activity from Sentinel 2 satellite data. The best model correctly identified 89% of land cover change events at the pixel-level, achieving a f-score of 0.93, a 79% improvement over the f-score of 0.52 achieved using a method designed for forested ecosystems based on trend analysis. Models have been deployed to operational use and are producing updated detections of habitat loss every 10 days. There is great potential for continuous monitoring of habitat loss in non-forest ecosystems with complex natural dynamics. A key limiting step is the development of accurately dated datasets of land cover change events with which to train machine-learning classifiers.",Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology,yes,Sentinel-2,Land Cover Change Detection,Vegetation,Classification,yes,99,93,96,89,,,,,,,,,,,
C,Pérez-Carabaza S.; Syrris V.; Kempeneers P.; Soille P.,CROP CLASSIFICATION FROM SENTINEL-2 TIME SERIES WITH TEMPORAL CONVOLUTIONAL NEURAL NETWORKS,International Geoscience and Remote Sensing Symposium (IGARSS),2021,Convolutional Neural Networks; Crop classification; Multi-temporal remote sensing images,"Automated crop identification tools are of interest to a wide range of applications related to the environment and agriculture including the monitoring of related policies such as the European Common Agriculture Policy. In this context, this work presents a parcel-based crop classification system which leverages on 1D convolutional neural network supervised learning capacity. For the training and evaluation of the model, we employ open and free data: (i) time series of Sentinel-2 optical data selected to cover the crop season of one year, and (ii) a cadastre-derived database providing detailed delineation of parcels. By considering the most dominant crop types and the temporal features of the optical data, the proposed lightweight approach discriminates a considerable number of crops with high accuracy. ©2021 IEEE",,yes,Sentinel-2,Crop classification,Agriculture,Classification,no,84.5,85.95,87.5,84.7,,,,,,,,,,,
J,"Kanwal, Rida; Rafaqat, Warda; Iqbal, Mansoor; Weiguo, Song",Data-Driven Approaches for Wildfire Mapping and Prediction Assessment Using a Convolutional Neural Network (CNN),REMOTE SENSING,2023,machine learning; wildfire assessment; CNN; random forest; fire occurrence,"As wildfires become increasingly perilous amidst Pakistan's expanding population and evolving environmental conditions, their global significance necessitates urgent attention and concerted efforts toward proactive measures and international cooperation. This research strives to comprehensively enhance wildfire prediction and management by implementing various measures to contribute to proactive mitigation in Pakistan. Additionally, the objective of this research was to acquire an extensive understanding of the factors that influence fire patterns in the country. For this purpose, we looked at the spatiotemporal patterns and causes of wildfires between 2000 and 2023 using descriptive analysis. The data analysis included a discussion on density-based clustering as well as the distribution of the data across four seasons over a period of six years. Factors that could indicate the probability of a fire occurrence such as weather conditions, terrain characteristics, and fuel availability encompass details about the soil, economy, and vegetation. We used a convolutional neural network (CNN) to extract features, and different machine learning (ML) techniques were implemented to obtain the best model for wildfire prediction. The majority of fires in the past six years have primarily occurred during the winter months in coastal locations. The occurrence of fires was accurately predicted by ML models such as random forest (RF), which outperformed competing models. Meanwhile, a CNN with 1D and 2D was used for more improvement in prediction by ML models. The accuracy increased from an 86.48 to 91.34 accuracy score by just using a CNN 1D. For more feature extraction, a CNN 2D was used on the same dataset, which led to state-of-the-art prediction results. A 96.91 accuracy score was achieved by further tuning the RF model on the total data. Data division by spatial and temporal changes was also used for the better prediction of fire, which can further be helpful for understanding the different prospects of wildfire. This research aims to advance wildfire prediction methodologies by leveraging ML techniques to explore the benefits and limitations of capturing complex patterns and relationships in large datasets. Policymakers, environmentalists, and scholars studying climate change can benefit greatly from the study's analytical approach, which may assist Pakistan in better managing and reducing wildfires.",Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology,yes,CBERS-4A,Wildfire prediction,Geohazards,Classification,yes,91.56,91.92,90.35,,,,,,,,,,,,
J,"Zhang, YH; Ge, TT; Tian, W; Liou, YA","Debris Flow Susceptibility Mapping Using Machine-Learning Techniques in Shigatse Area, China",REMOTE SENSING,2019,debris flow susceptibility; remote sensing; GIS; oversampling methods; back propagation neural network; one-dimensional convolutional neural network; decision tree; random forest; extreme gradient boosting,"Debris flows have been always a serious problem in the mountain areas. Research on the assessment of debris flows susceptibility (DFS) is useful for preventing and mitigating debris flow risks. The main purpose of this work is to study the DFS in the Shigatse area of Tibet, by using machine learning methods, after assessing the main triggering factors of debris flows. Remote sensing and geographic information system (GIS) are used to obtain datasets of topography, vegetation, human activities and soil factors for local debris flows. The problem of debris flow susceptibility level imbalances in datasets is addressed by the Borderline-SMOTE method. Five machine learning methods, i.e., back propagation neural network (BPNN), one-dimensional convolutional neural network (1D-CNN), decision tree (DT), random forest (RF), and extreme gradient boosting (XGBoost) have been used to analyze and fit the relationship between debris flow triggering factors and occurrence, and to evaluate the weight of each triggering factor. The ANOVA and Tukey HSD tests have revealed that the XGBoost model exhibited the best mean accuracy (0.924) on ten-fold cross-validation and the performance was significantly better than that of the BPNN (0.871), DT (0.816), and RF (0.901). However, the performance of the XGBoost did not significantly differ from that of the 1D-CNN (0.914). This is also the first comparison experiment between XGBoost and 1D-CNN methods in the DFS study. The DFS maps have been verified by five evaluation methods: Precision, Recall, F1 score, Accuracy and area under the curve (AUC). Experiments show that the XGBoost has the best score, and the factors that have a greater impact on debris flows are aspect, annual average rainfall, profile curvature, and elevation.",Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology,yes,MODIS,Debris Flow Susceptibility Mapping,Geohazards,Classification,no,90.6,90.1,91.4,90.6,,,,,,,,,,,
J,"Li, Qianjing; Tian, Jia; Tian, Qingjiu",Deep Learning Application for Crop Classification via Multi-Temporal Remote Sensing Images,AGRICULTURE-BASEL,2023,crop type classification; deep learning; multi-temporal; remote sensing,"The combination of multi-temporal images and deep learning is an efficient way to obtain accurate crop distributions and so has drawn increasing attention. However, few studies have compared deep learning models with different architectures, so it remains unclear how a deep learning model should be selected for multi-temporal crop classification, and the best possible accuracy is. To address this issue, the present work compares and analyzes a crop classification application based on deep learning models and different time-series data to exploit the possibility of improving crop classification accuracy. Using Multi-temporal Sentinel-2 images as source data, time-series classification datasets are constructed based on vegetation indexes (VIs) and spectral stacking, respectively, following which we compare and evaluate the crop classification application based on time-series datasets and five deep learning architectures: (1) one-dimensional convolutional neural networks (1D-CNNs), (2) long short-term memory (LSTM), (3) two-dimensional-CNNs (2D-CNNs), (4) three-dimensional-CNNs (3D-CNNs), and (5) two-dimensional convolutional LSTM (ConvLSTM2D). The results show that the accuracy of both 1D-CNN (92.5%) and LSTM (93.25%) is higher than that of random forest (similar to 91%) when using a single temporal feature as input. The 2D-CNN model integrates temporal and spatial information and is slightly more accurate (94.76%), but fails to fully utilize its multi-spectral features. The accuracy of 1D-CNN and LSTM models integrated with temporal and multi-spectral features is 96.94% and 96.84%, respectively. However, neither model can extract spatial information. The accuracy of 3D-CNN and ConvLSTM2D models is 97.43% and 97.25%, respectively. The experimental results show limited accuracy for crop classification based on single temporal features, whereas the combination of temporal features with multi-spectral or spatial information significantly improves classification accuracy. The 3D-CNN and ConvLSTM2D models are thus the best deep learning architectures for multi-temporal crop classification. However, the ConvLSTM architecture combining recurrent neural networks and CNNs should be further developed for multi-temporal image crop classification.",Agriculture,yes,Sentinel-2,Crop classification,Agriculture,Classification,no,96.84,,,,,,,96,,,,,,,
J,"Maier, PM; Keller, S; Hinz, S",Deep Learning with WASI Simulation Data for Estimating Chlorophyll a Concentration of Inland Water Bodies,REMOTE SENSING,2021,machine learning; regression; CNN; artificial neural network; radiative transfer model; WASI; hyperspectral data; algae; chlorophyll a; downsampling,"Information about the chlorophyll a concentration of inland water bodies is essential for water monitoring. This study focuses on estimating chlorophyll a with remote sensing data, and machine learning (ML) approaches on the real-world SpecWa dataset. We adapt and apply a one-dimensional convolutional neural network (1D CNN) as a deep learning architecture for the first time to address this estimation. Since such a DL approach requires a large amount of data for its training, we rely on simulation data generated by the Water Color Simulator (WASI). This simulation is prepared accordingly and includes a knowledge-based water composition with two origins of the chlorophyll a concentration. Therefore, the training data is independent of the real-world SpecWa dataset, which is challenging for any ML approach. We define two spectral downsampling approaches as a pre-processing step, representing the hyperspectral EnMAP satellite mission (SR-EnMAP) and the multispectral Sentinel-2 mission (SR-Sentinel). Subsequently, we train a Random Forest, an artificial neural network, a band-ratio approach, and the 1D CNN on the WASI-generated simulation training dataset. Finally, all ML models are evaluated on the real SpecWa dataset. For both downsampled data, the 1D CNN outperforms the other ML models. On the finer resolved SR-EnMAP data it achieves an R-2=81.9%, RMSE=12.4 mu g L-1, and MAE=6.7 mu g L-1. Besides, the 1D CNN's performance decreases on the SR-Sentinel data to R-2=62.4%. When focusing on the individual water bodies of the SpecWa dataset, the most significant differences exist between natural and artificial water bodies. We discover that the applied models estimate the chlorophyll a concentration of most natural water bodies satisfyingly. In sum, the newly DL approach can estimate the chlorophyll a values of unknown inland water bodies successfully, although it is trained on an entire simulation dataset.",Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology,yes,Sentinel-2,Estimating Chlorophyll a Concentration of Inland Water Bodies,Water,Regression,no,,,,,,,,,,,,0.624,19.3,14.6,Chl-a (mg/m3)
J,"Ojaghi, S; Bouroubi, Y; Foucher, S; Bergeron, M; Seynat, C",Deep Learning-Based Emulation of Radiative Transfer Models for Top-of-Atmosphere BRDF Modelling Using Sentinel-3 OLCI,REMOTE SENSING,2023,deep learning; RTMSs; emulator; BRDF; 1D-CNN; PROSAIL; 6S; Sentinel-3 OLCI,"The Bidirectional Reflectance Distribution Function (BRDF) defines the anisotropy of surface reflectance and plays a fundamental role in many remote sensing applications. This study proposes a new machine learning-based model for characterizing the BRDF. The model integrates the capability of Radiative Transfer Models (RTMs) to generate simulated remote sensing data with the power of deep neural networks to emulate, learn and approximate the complex pattern of physical RTMs for BRDF modeling. To implement this idea, we used a one-dimensional convolutional neural network (1D-CNN) trained with a dataset simulated using two widely used RTMs: PROSAIL and 6S. The proposed 1D-CNN consists of convolutional, max poling, and dropout layers that collaborate to establish a more efficient relationship between the input and output variables from the coupled PROSAIL and 6S yielding a robust, fast, and accurate BRDF model. We evaluated the proposed approach performance using a collection of an independent testing dataset. The results indicated that the proposed framework for BRDF modeling performed well at four simulated Sentinel-3 OLCI bands, including Oa04 (blue), Oa06 (green), Oa08 (red), and Oa17 (NIR), with a mean correlation coefficient of around 0.97, and RMSE around 0.003 and an average relative percentage error of under 4%. Furthermore, to assess the performance of the developed network in the real domain, a collection of multi-temporals OLCI real data was used. The results indicated that the proposed framework has a good performance in the real domain with a coefficient correlation (R-2), 0.88, 0.76, 0.7527, and 0.7560 respectively for the blue, green, red, and NIR bands.",Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology,yes,Sentinel-3,The Bidirectional Reflectance Distribution Function (BRDF) defines the surface reflectance anisotropy as a function of sun-surface-sensor geometry and surface and sensor properties.,Others,Regression,no,,,,,,,,,,,,0.97,3,,Reflectance
J,"Zhang, Hankui K.; Roy, David P.; Luo, Dong",Demonstration of large area land cover classification with a one dimensional convolutional neural network applied to single pixel temporal metric percentiles,REMOTE SENSING OF ENVIRONMENT,2023,Land cover; Time series; Temporal metric percentiles; Convolutional neural network; Random forest; Deep learning; Large area classification; Landsat,"Over large areas, land cover classification has conventionally been undertaken using satellite time series. Typically temporal metric percentiles derived from single pixel location time series have been used to take advantage of spectral differences among land cover classes over time and to minimize the impact of missing observations. Deep convolutional neural networks (CNNs) have demonstrated potential for land cover classification of single date images. However, over large areas and using time series their application is complicated because they are sensitive to missing observations and they may misclassify small and spatially fragmented surface features due to their spatial patch-based implementation. This study demonstrates, for the first time, a one-dimensional (1D) CNN single pixel time series land classification approach that uses temporal percentile metrics and that does not have these issues. This is demonstrated for all the Conterminous United States (CONUS) considering two different 1D CNN structures with 5 and 8 layers, respectively. CONUS 30 m land cover classifications were derived using all the available Landsat-5 and -7 imagery over a seven-month growing season in 2011 with 3.3 million 30 m land cover class labelled samples extracted from the contemporaneous CONUS National Land Cover Database (NLCD) 16 class land cover product. The 1D CNNs and, a conventional random forest model, were trained using 10%, 50% and 90% samples, and the classification accuracies were evaluated with an independent 10% proportion. Temporal metrics were classified using 5, 7 and 9 percentiles for each of five Landsat reflective wavelength bands and their eight band ratios. The CONUS and detailed 150 x 150 km classification results demonstrate that the approach is effective at scale and locally. The 1D CNN classification land cover class boundaries were preserved for small axis dimension features, such as roads and rivers, with no stripes or anomalous spatial patterns. The 8-layer 1D CNN provided the highest overall classification accuracies and both the 5-layer and 8-layer 1D CNN architectures provided higher accuracies than the random forest by 1.9% - 2.8% which as all the accuracies were > 83% is a meaningful increase. The CONUS overall classification accuracies increased marginally with the number of percentiles (86.21%, 86.40%, and 86.43% for 5, 7 and 9 percentiles, respectively) using the 8-layer 1D-CNN. Class specific producer and user accuracies were quantified, with lower accuracies for the developed land, crop and pasture/hay classes, but no systematic pattern among classes with respect to the number of temporal percentiles used. Application of the trained model to a different year of CONUS Landsat ARD showed moderately decreased accuracy (80.79% for 7 percentiles) that we illustrate is likely due to different intra-annual surface variations between years. These encouraging results are discussed with recommended research for deep learning using temporal metric percentiles.",Environmental Sciences & Ecology; Remote Sensing; Imaging Science & Photographic Technology,yes,Landsat-5,Demonstration of large area land cover classification,Vegetation,Classification,no,83,,,,,,,,,,,,,,
J,"Zhang, Hankui K.; Roy, David P.; Luo, Dong",Demonstration of large area land cover classification with a one dimensional convolutional neural network applied to single pixel temporal metric percentiles,REMOTE SENSING OF ENVIRONMENT,2023,Land cover; Time series; Temporal metric percentiles; Convolutional neural network; Random forest; Deep learning; Large area classification; Landsat,"Over large areas, land cover classification has conventionally been undertaken using satellite time series. Typically temporal metric percentiles derived from single pixel location time series have been used to take advantage of spectral differences among land cover classes over time and to minimize the impact of missing observations. Deep convolutional neural networks (CNNs) have demonstrated potential for land cover classification of single date images. However, over large areas and using time series their application is complicated because they are sensitive to missing observations and they may misclassify small and spatially fragmented surface features due to their spatial patch-based implementation. This study demonstrates, for the first time, a one-dimensional (1D) CNN single pixel time series land classification approach that uses temporal percentile metrics and that does not have these issues. This is demonstrated for all the Conterminous United States (CONUS) considering two different 1D CNN structures with 5 and 8 layers, respectively. CONUS 30 m land cover classifications were derived using all the available Landsat-5 and -7 imagery over a seven-month growing season in 2011 with 3.3 million 30 m land cover class labelled samples extracted from the contemporaneous CONUS National Land Cover Database (NLCD) 16 class land cover product. The 1D CNNs and, a conventional random forest model, were trained using 10%, 50% and 90% samples, and the classification accuracies were evaluated with an independent 10% proportion. Temporal metrics were classified using 5, 7 and 9 percentiles for each of five Landsat reflective wavelength bands and their eight band ratios. The CONUS and detailed 150 x 150 km classification results demonstrate that the approach is effective at scale and locally. The 1D CNN classification land cover class boundaries were preserved for small axis dimension features, such as roads and rivers, with no stripes or anomalous spatial patterns. The 8-layer 1D CNN provided the highest overall classification accuracies and both the 5-layer and 8-layer 1D CNN architectures provided higher accuracies than the random forest by 1.9% - 2.8% which as all the accuracies were > 83% is a meaningful increase. The CONUS overall classification accuracies increased marginally with the number of percentiles (86.21%, 86.40%, and 86.43% for 5, 7 and 9 percentiles, respectively) using the 8-layer 1D-CNN. Class specific producer and user accuracies were quantified, with lower accuracies for the developed land, crop and pasture/hay classes, but no systematic pattern among classes with respect to the number of temporal percentiles used. Application of the trained model to a different year of CONUS Landsat ARD showed moderately decreased accuracy (80.79% for 7 percentiles) that we illustrate is likely due to different intra-annual surface variations between years. These encouraging results are discussed with recommended research for deep learning using temporal metric percentiles.",Environmental Sciences & Ecology; Remote Sensing; Imaging Science & Photographic Technology,yes,Landsat-7,Demonstration of large area land cover classification,Vegetation,Classification,no,83,,,,,,,,,,,,,,
J,"Nguyen, Chi; Tan, Chang Wei; Daly, Edoardo; Pauwels, Valentijn R. N.",Efficient analysis of hydrological connectivity using 1D and 2D Convolutional Neural Networks,ADVANCES IN WATER RESOURCES,2023,Convolutional neural network; Functional connectivity; Potential connection length,"Understanding hydrological connectivity is essential to investigate ecological processes in river catchments and floodplains. Assessing flooding behavior, including flooded areas and connection times, is required to analyze hydrological connectivity in river floodplains. Deep learning, especially Convolutional Neural Networks (CNNs), is an attractive alternative to hydrodynamic modeling, which is more computationally expensive. This paper aims to develop a methodology to analyze the functional connectivity in remote and field measurement data-scarce areas using remote sensing data, CNN models, and connectivity metrics. The northern Lakes of the Narran River catchment, located in the Condamine-Balonne River floodplain in New South Wales, Australia, is the showcase for this method. One-dimensional CNN and two-dimensional U-Net configurations were applied and yielded comparable flood extents to the satellite images with Hit Rate values of 0.853 and 0.873, respectively. Two algorithms for determining hydrological connectivity were investigated, including the geostatistical Connectivity Function (CF) and the newly proposed Potential Connection Length (PCL). It was found that the connection along the main Narran River stream was more substantial than between the river and the floodplain lakes. The analysis using the PCL shows that the connectivity patterns in different stages of a flood event can vary depending on the initial condition of the floodplain. The overall conclusion from this work is that hydrological connectivity can be assessed computationally efficiently using only remote sensing, discharge data, and CNN models.",Water Resources,yes,Sentinel-2,Hydrological connectivity,Water,Classification,no,,,81.8,,,,,,,,,,,,
J,"Nguyen, Chi; Tan, Chang Wei; Daly, Edoardo; Pauwels, Valentijn R. N.",Efficient analysis of hydrological connectivity using 1D and 2D Convolutional Neural Networks,ADVANCES IN WATER RESOURCES,2023,Convolutional neural network; Functional connectivity; Potential connection length,"Understanding hydrological connectivity is essential to investigate ecological processes in river catchments and floodplains. Assessing flooding behavior, including flooded areas and connection times, is required to analyze hydrological connectivity in river floodplains. Deep learning, especially Convolutional Neural Networks (CNNs), is an attractive alternative to hydrodynamic modeling, which is more computationally expensive. This paper aims to develop a methodology to analyze the functional connectivity in remote and field measurement data-scarce areas using remote sensing data, CNN models, and connectivity metrics. The northern Lakes of the Narran River catchment, located in the Condamine-Balonne River floodplain in New South Wales, Australia, is the showcase for this method. One-dimensional CNN and two-dimensional U-Net configurations were applied and yielded comparable flood extents to the satellite images with Hit Rate values of 0.853 and 0.873, respectively. Two algorithms for determining hydrological connectivity were investigated, including the geostatistical Connectivity Function (CF) and the newly proposed Potential Connection Length (PCL). It was found that the connection along the main Narran River stream was more substantial than between the river and the floodplain lakes. The analysis using the PCL shows that the connectivity patterns in different stages of a flood event can vary depending on the initial condition of the floodplain. The overall conclusion from this work is that hydrological connectivity can be assessed computationally efficiently using only remote sensing, discharge data, and CNN models.",Water Resources,yes,Landsat-5,Hydrological connectivity,Water,Classification,no,,,81.8,,,,,,,,,,,,
J,"Nguyen, Chi; Tan, Chang Wei; Daly, Edoardo; Pauwels, Valentijn R. N.",Efficient analysis of hydrological connectivity using 1D and 2D Convolutional Neural Networks,ADVANCES IN WATER RESOURCES,2023,Convolutional neural network; Functional connectivity; Potential connection length,"Understanding hydrological connectivity is essential to investigate ecological processes in river catchments and floodplains. Assessing flooding behavior, including flooded areas and connection times, is required to analyze hydrological connectivity in river floodplains. Deep learning, especially Convolutional Neural Networks (CNNs), is an attractive alternative to hydrodynamic modeling, which is more computationally expensive. This paper aims to develop a methodology to analyze the functional connectivity in remote and field measurement data-scarce areas using remote sensing data, CNN models, and connectivity metrics. The northern Lakes of the Narran River catchment, located in the Condamine-Balonne River floodplain in New South Wales, Australia, is the showcase for this method. One-dimensional CNN and two-dimensional U-Net configurations were applied and yielded comparable flood extents to the satellite images with Hit Rate values of 0.853 and 0.873, respectively. Two algorithms for determining hydrological connectivity were investigated, including the geostatistical Connectivity Function (CF) and the newly proposed Potential Connection Length (PCL). It was found that the connection along the main Narran River stream was more substantial than between the river and the floodplain lakes. The analysis using the PCL shows that the connectivity patterns in different stages of a flood event can vary depending on the initial condition of the floodplain. The overall conclusion from this work is that hydrological connectivity can be assessed computationally efficiently using only remote sensing, discharge data, and CNN models.",Water Resources,yes,Landsat-7,Hydrological connectivity,Water,Classification,no,,,81.8,,,,,,,,,,,,
J,"Nguyen, Chi; Tan, Chang Wei; Daly, Edoardo; Pauwels, Valentijn R. N.",Efficient analysis of hydrological connectivity using 1D and 2D Convolutional Neural Networks,ADVANCES IN WATER RESOURCES,2023,Convolutional neural network; Functional connectivity; Potential connection length,"Understanding hydrological connectivity is essential to investigate ecological processes in river catchments and floodplains. Assessing flooding behavior, including flooded areas and connection times, is required to analyze hydrological connectivity in river floodplains. Deep learning, especially Convolutional Neural Networks (CNNs), is an attractive alternative to hydrodynamic modeling, which is more computationally expensive. This paper aims to develop a methodology to analyze the functional connectivity in remote and field measurement data-scarce areas using remote sensing data, CNN models, and connectivity metrics. The northern Lakes of the Narran River catchment, located in the Condamine-Balonne River floodplain in New South Wales, Australia, is the showcase for this method. One-dimensional CNN and two-dimensional U-Net configurations were applied and yielded comparable flood extents to the satellite images with Hit Rate values of 0.853 and 0.873, respectively. Two algorithms for determining hydrological connectivity were investigated, including the geostatistical Connectivity Function (CF) and the newly proposed Potential Connection Length (PCL). It was found that the connection along the main Narran River stream was more substantial than between the river and the floodplain lakes. The analysis using the PCL shows that the connectivity patterns in different stages of a flood event can vary depending on the initial condition of the floodplain. The overall conclusion from this work is that hydrological connectivity can be assessed computationally efficiently using only remote sensing, discharge data, and CNN models.",Water Resources,yes,Landsat-8,Hydrological connectivity,Water,Classification,no,,,81.8,,,,,,,,,,,,
J,X. Wan; J. Wan; M. Xu; S. Liu; H. Sheng; Y. Chen; X. Zhang,Enteromorpha Coverage Information Extraction by 1D-CNN and Bi-LSTM Networks Considering Sample Balance From GOCI Images,IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing,2021,Enteromorpha prolifera (EP);geostationary ocean color imager (GOCI);neural network;sample balance,"Remote sensing technology is widely used for the dynamic monitoring of Enteromorpha prolifera (EP) blooms due to its high temporal resolution and large scale monitoring. Recently, deep learning(DL) methods have been applied to EP analysis due to their excellent feature representation. However, EP information extraction methods based on DL from low-spatial-resolution satellite images are still immature. The main problems with such methods include the insufficiency of spectral and spatial feature learning in low-resolution satellite images, as well as the sample imbalance that DL-based neural networks face in EP information extraction. To solve the above problems, a neural network-based EP extraction method considering sample balance is proposed in this article and named EP rough-then-accurate extraction network. The method consists of two components: EP rough extraction, a strategy that attends to sample balance, and EP accurate extraction, a deep neural network based on one-dimensional convolutional neural network and bidirectional long short-term memory (Bi-LSTM), which fully considers the learned spectral information of each pixel and interpixel contextual dependencies. Geostationary Ocean Color Imager images with 500-m resolution were applied as the LR images in the experiments. The experimental results show that the proposed method has the capability to enhance adaptability in areas with different EP densities (achieving stable and excellent performance) and exhibits at least a 10% gain in F1-score and at least a 6% gain in IoU in extracting EP coverage information over other representative and traditional EP extraction methods in the Yellow Sea region.",,yes,GOCI,Enteromorpha prolifera (EP) blooms (coastal areas),Water,Classification,no,95.2,81.6,,,,,,,69,,,,,,
C,Ding C.; Zhang X.; Ma S.; Han W.; Lu Y.; Yin J.,"Estuary water quality classification through deep learning image segmentation, an example of Hangzhou Bay","2021 9th International Conference on Agro-Geoinformatics, Agro-Geoinformatics 2021",2021,convolutional neural networks; image segmentation; Suspended sediment concentration; UNet,"Suspended sediment plays a dual role in the aquatic ecosystems. It serves an important part of the aquatic nutrient cycle but is also a pollutant in aquatic ecosystems. Traditional methods of measuring suspended sediment concentration (SSC) are mainly in-situ sampling and laboratory analysis. Through optical sensors carried by satellites or airplanes, large-scale SSC is possible to be acquired, which helps to improve our understanding of connections of source, sink and pathway. Although lots of efforts have been done in water quality modeling, methods utilized are mainly multi-layer perceptrons, machine learning algorithms or physio-chemical models, few tries on convolutional neural networks have been done. Here we take the Landsat image of Hangzhou Bay as an example. Based on the inversion algorithm the water quality classification is conducted through by 1D-CNN and 2D-UNet model. Best match between the band and reflectance of SSC received by the sensor are carefully selected as input. Both models prove feasible with convincing accuracy and precision, despite some discrepancies in details. Water quality classification could be furtherly completed if taking multi-index of water into account. © 2021 IEEE.",,yes,Landsat-8,Water quality classification,Water,Classification,no,97.14,,97.16,,,,,,,,91.91,,,,
J,"Xu, Zhenheng; Sun, Hao; Zhang, Tian; Xu, Huanyu; Wu, Dan; Gao, JinHua",Evaluating established deep learning methods in constructing integrated remote sensing drought index: A case study in China,AGRICULTURAL WATER MANAGEMENT,2023,Agricultural drought; Remote sensing; Data driven; Deep learning; Machine learning; Inductive bias,"Agricultural drought seriously threatens the food and ecological security of most of the world's developing countries. Data-driven integrated agricultural drought index with remote sensing provides an effective tool to monitor, evaluate, and predict the agricultural drought. However, there is still a lack of comprehensive analytical work on taking the most effective machine learning (ML) and deep learning (DL) methods to construct such integrated drought index. In other words, it is still unclear whether the recent DL methods can improve inte-grated drought monitoring as compared with the currently widely used ML methods. Therefore, we critically evaluated the performances of four representative DL methods (represents the four currently popular DL network types) i.e., Entity Embedding Deep Neural Network (EEDNN), One-dimensional Convolutional Neural Network (1D-CNN), Gated Recurrent Unit (GRU), and Self-Attention Mechanism (SAM) and three widely used tree-based ML methods i.e., Cubist, Random Forest (RF), and Light Gradient Boosting Machine (LGBM), through con-structing a QuickDRI like integrated drought index (abbreviated as QuickDRI-China). About 30 years of mete-orological data, 14 years of remote sensing data, and various biophysical variables in China such as land use/land cover, available water capacity, irrigated agriculture, elevation, and ecoregion were employed in this study. Results showed that the EEDNN performed best, followed by the RF and LGBM, and then the other methods including the currently wide used Cubist, according to the station accuracy evaluations, spatial description evaluations, and responses to specific drought event. The tree-based ML methods such as RF and LGBM are still competitive in constructing the integrated agricultural drought index at the current stage. However, the higher accuracy, the smoother spatial description, and the more responsive ability of the EEDNN demonstrate great potential of DL methods. The future integrated agricultural drought monitoring with remote sensing should develop a specialized DL network for heterogeneous agricultural drought features.",Agriculture; Water Resources,yes,MODIS,Drought index,Geohazards,Regression,no,,,,,,,,,,,,0.907,0.31,,Drought
J,"Zhao, HW; Duan, SB; Liu, J; Sun, L; Reymondin, L",Evaluation of Five Deep Learning Models for Crop Type Mapping Using Sentinel-2 Time Series Images with Missing Information,REMOTE SENSING,2021,crop type mapping; Sentinel-2; missing information; time series data; CNN; LSTM; GRU,"Accurate crop type maps play an important role in food security due to their widespread applicability. Optical time series data (TSD) have proven to be significant for crop type mapping. However, filling in missing information due to clouds in optical imagery is always needed, which will increase the workload and the risk of error transmission, especially for imagery with high spatial resolution. The development of optical imagery with high temporal and spatial resolution and the emergence of deep learning algorithms provide solutions to this problem. Although the one-dimensional convolutional neural network (1D CNN), long short-term memory (LSTM), and gate recurrent unit (GRU) models have been used to classify crop types in previous studies, their ability to identify crop types using optical TSD with missing information needs to be further explored due to their different mechanisms for handling invalid values in TSD. In this research, we designed two groups of experiments to explore the performances and characteristics of the 1D CNN, LSTM, GRU, LSTM-CNN, and GRU-CNN models for crop type mapping using unfilled Sentinel-2 (Sentinel-2) TSD and to discover the differences between unfilled and filled Sentinel-2 TSD based on the same algorithm. A case study was conducted in Hengshui City, China, of which 70.3% is farmland. The results showed that the 1D CNN, LSTM-CNN, and GRU-CNN models achieved acceptable classification accuracies (above 85%) using unfilled TSD, even though the total missing rate of the sample values was 43.5%; these accuracies were higher and more stable than those obtained using filled TSD. Furthermore, the models recalled more samples on crop types with small parcels when using unfilled TSD. Although LSTM and GRU models did not attain accuracies as high as the other three models using unfilled TSD, their results were almost close to those with filled TSD. This research showed that crop types could be identified by deep learning features in Sentinel-2 dense time series images with missing information due to clouds or cloud shadows randomly, which avoided spending a lot of time on missing information reconstruction.",Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology,yes,Sentinel-2,Crop type maps,Agriculture,Classification,no,86.43,84.71,85.79,83.66,,,,,,,,,,,
C,G. S. Phartiyal; L. S. Khangarot; D. Singh,Impact of Permuted Spectral Neighborhood of High-Dimensional Msts Rs Data on Crop Classification Performance with DNN Models,IGARSS 2023 - 2023 IEEE International Geoscience and Remote Sensing Symposium,2023,localized spectral information;CNNs;multi-sensor;crop classification;time-series,"It is still a challenge for existing DNN based models to synergistically exploit the spatial, temporal, and especially spectral information of a crop present in multi-sensor time series (MSTS) remote sensing (RS) images and provide accurate crop classification while keeping the generalization ability of DNN models high. This imbalance requires investigation and demands novel CNN and RNN model-based approaches that can address the issue. The novel models proposed in this study involve the concepts of permuted localized spectral convolutions, localized spatial convolutions, and bi-directional recurrent units. The permuted spectral band stacking strategy is explored in this study to strengthen the influence of the spectral information. Overall, 6 models are proposed namely; Perm-1D-CNN, Perm-3D-CNN, Perm-RNN, Perm-1D-CRNN, Perm-2D-CRNN, and Perm-3D-CRNN. The qualitative and quantitative assessments reflect the higher generalization ability of the Perm-3D-CRNN along with its high classification accuracy. Also, the impact of spectral band permutations and localized spectral convolutions on the performance of DNN models is significant toward improved generalization.",Time series analysis;Stacking;Crops;Bidirectional control;Data models;Remote sensing,yes,Sentinel-2,Crop classification,Agriculture,Classification,no,95.66,,,,,,,,,,,,,,
J,"Luo, X; Tong, XH; Hu, ZW; Wu, GF",Improving Urban Land Cover/Use Mapping by Integrating A Hybrid Convolutional Neural Network and An Automatic Training Sample Expanding Strategy,REMOTE SENSING,2020,remote sensing; land cover classification; spectral feature; context feature; convolutional neural networks,"Moderate spatial resolution (MSR) satellite images, which hold a trade-off among radiometric, spectral, spatial and temporal characteristics, are extremely popular data for acquiring land cover information. However, the low accuracy of existing classification methods for MSR images is still a fundamental issue restricting their capability in urban land cover mapping. In this study, we proposed a hybrid convolutional neural network (H-ConvNet) for improving urban land cover mapping with MSR Sentinel-2 images. The H-ConvNet was structured with two streams: one lightweight 1D ConvNet for deep spectral feature extraction and one lightweight 2D ConvNet for deep context feature extraction. To obtain a well-trained 2D ConvNet, a training sample expansion strategy was introduced to assist context feature learning. The H-ConvNet was tested in six highly heterogeneous urban regions around the world, and it was compared with support vector machine (SVM), object-based image analysis (OBIA), Markov random field model (MRF) and a newly proposed patch-based ConvNet system. The results showed that the H-ConvNet performed best. We hope that the proposed H-ConvNet would benefit for the land cover mapping with MSR images in highly heterogeneous urban regions.",Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology,yes,Sentinel-2,Urban land cover maps,Urban,Classification,no,77.55,,,,,,,,,,,,,,
J,"Sabo, Filip; Meroni, Michele; Waldner, Francois; Rembold, Felix",Is deeper always better? Evaluating deep learning models for yield forecasting with small data,ENVIRONMENTAL MONITORING AND ASSESSMENT,2023,Convolutional neural networks; Agriculture; Remote sensing; Food security,"Predicting crop yields, and especially anomalously low yields, is of special importance for food insecure countries. In this study, we investigate a flexible deep learning approach to forecast crop yield at the provincial administrative level based on deep 1D and 2D convolutional neural networks using limited data. This approach meets the operational requirements-public and global records of satellite data in an application ready format with near real time updates-and can be transferred to any country with reliable yield statistics. Three-dimensional histograms of normalized difference vegetation index (NDVI) and climate data are used as input to the 2D model, while simple administrative-level time series averages of NDVI and climate data to the 1D model. The best model architecture is automatically identified during efficient and extensive hyperparameter optimization. To demonstrate the relevance of this approach, we hindcast (2002-2018) the yields of Algeria's three main crops (barley, durum and soft wheat) and contrast the model's performance with machine learning algorithms and conventional benchmark models used in a previous study. Simple benchmarks such as peak NDVI remained challenging to outperform while machine learning models were superior to deep learning models for all forecasting months and all tested crops. We attribute the poor performance of deep learning to the small size of the dataset available.",Environmental Sciences & Ecology,yes,MODIS,Crop yield prediction,Agriculture,Regression,no,,,,,,,,,,,,,,,
C,Y. Song; Z. Zhang; R. K. Baghbaderani; F. Wang; Y. Qu; C. Stuttsy; H. Qi,Land Cover Classification for Satellite Images Through 1D CNN,2019 10th Workshop on Hyperspectral Imaging and Signal Processing: Evolution in Remote Sensing (WHISPERS),2019,Satellite Image;Land Cover Classification;1D CNN;Deep Learning;Spectral Unmixing,"Land cover classification of satellite imagery can provide significant information for many applications, including surface analysis, environmental monitoring, building reconstruction, etc. Land cover classification has been generally performed using unmixing-based or shallow/deep learning approaches, among which the unmixing-based approaches suffer from stability issues due to the complex intrinsic properties of the data, deep learning-based approaches like 2D CNN requires large labeled training set which is often unavailable in satellite images and small ground truth collection leads to spatial discontinuities (as shown in Fig. 1), making 2D CNN approaches unviable. In this paper, we first propose a 1D convolution neural network-based framework applied to each pixel in the spectral domain where we extract descriptive local features for improved classification. Experimental results demonstrate superior classification accuracy through comparison with traditional unmixing-based and neural network methods using just limited number of training samples.",,yes,WorldView-3,Land cover classification,Urban,Classification,no,89.18,,,,,,,,,,,,,,
J,"Fan, Xiangsuo; Chen, Lin; Xu, Xinggui; Yan, Chuan; Fan, Jinlong; Li, Xuyang",Land Cover Classification of Remote Sensing Images Based on Hierarchical Convolutional Recurrent Neural Network,FORESTS,2023,pixel classification; CNN; RNN; RS image classification,"Convolutional neural networks (CNNs) and recurrent neural networks (RNNs) have gained improved results in remote sensing image data classification. Multispectral image classification can benefit from the rich spectral information extracted by these models for land cover classification. This paper proposes a classification model called a hierarchical convolutional recurrent neural network (HCRNN) to combine the CNN and RNN modules for pixel-level classification of multispectral remote sensing images. In the HCRNN model, the original 13-band information from Sentinel-2 is transformed into a 1D multispectral sequence using a fully connected layer. It is then reshaped into a 3D multispectral feature matrix. The 2D-CNN features are extracted and used as inputs to the corresponding hierarchical RNN. The feature information at each level is adapted to the same convolution size. This network structure fully leverages the advantages of CNNs and RNNs to extract temporal and spatial features from the spectral data, leading to high-precision pixel-level multispectral remote sensing image classification. The experimental results demonstrate that the overall accuracy of the HCRNN model on the Sentinel-2 dataset reaches 97.62%, which improves the performance by 1.78% compared to the RNN model. Furthermore, this study focused on the changes in forest cover in the study area of Laibin City, Guangxi Zhuang Autonomous Region, which was 7997.1016 km2, 8990.4149 km2, and 8103.0020 km2 in 2017, 2019, and 2021, respectively, with an overall trend of a small increase in the area covered.",Forestry,yes,Sentinel-2,Land cover classification,Urban,Classification,no,92.79,,,,,,,90.31,,,,,,,
J,"Sun, HR; Wang, L; Lin, RC; Zhang, Z; Zhang, BZ",Mapping Plastic Greenhouses with Two-Temporal Sentinel-2 Images and 1D-CNN Deep Learning,REMOTE SENSING,2021,plastic greenhouses; sustainable agriculture; sentinel-2; 1D-CNN; red-edge bands,"Plastic greenhouses (PGs) are widely built near cities in China to produce vegetables and fruits. In order to promote sustainable agriculture, rural landscape construction, and better manage water resources, numerous remote sensing methods have been developed to identify and monitor the distribution of PGs, of which many map PGs based on spectral responses and geometric shapes. In this study, we proposed a new fine- and coarse-scale mapping approach using two-temporal Sentinel-2 images with various seasonal characteristics and a one-dimensional convolutional neural network (1D-CNN). Having applied this approach in a pilot area study, the results were summarized as follows: (1) A time-series analysis of Sentinel-2 images showed that the reflectance of greenhouses changes during crop growth and development. In particular, the red-edge and near-infrared bands undergo a significant increase and then decrease during the whole crop growth period. Thus, two critical period images, containing a substantial difference in greenhouse reflectance, were sufficient to carry out an accurate and efficient mapping result. (2) The 1D-CNN classifier was used to map greenhouses by capturing subtle details and the overall trend of the spectrum curve. Overall, our approach showed higher classification accuracy than other approaches using support vector machines (SVM) or random forests (RF). In addition, the greenhouse area identified was highly consistent with the existing surfaces observed in very high-resolution images, with a kappa co-efficient of 0.81. (3) The narrow band feature differences (red-edge and near infrared narrow bands) in two-temporal Sentinel-2 images played a significant role in high-precision greenhouse mapping. The classification accuracy with narrow band features was much better than the maps produced without narrow band features. This scheme provided a method to digitize greenhouse precisely and publish its statistics for free, which enable advanced decision support for agriculture management.",Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology,yes,Sentinel-2,Mapping Plastic Greenhouses,Urban,Classification,no,91.38,,,,87.13,86.88,,80,,,,,,,
J,"Zhang, WC; Liu, HB; Wu, W; Zhan, LQ; Wei, J",Mapping Rice Paddy Based on Machine Learning with Sentinel-2 Multi-Temporal Data: Model Comparison and Transferability,REMOTE SENSING,2020,rice; convolutional neural network; F1 score; sentinel-2; transfer,"Rice is an important agricultural crop in the Southwest Hilly Area, China, but there has been a lack of efficient and accurate monitoring methods in the region. Recently, convolutional neural networks (CNNs) have obtained considerable achievements in the remote sensing community. However, it has not been widely used in mapping a rice paddy, and most studies lack the comparison of classification effectiveness and efficiency between CNNs and other classic machine learning models and their transferability. This study aims to develop various machine learning classification models with remote sensing data for comparing the local accuracy of classifiers and evaluating the transferability of pretrained classifiers. Therefore, two types of experiments were designed: local classification experiments and model transferability experiments. These experiments were conducted using cloud-free Sentinel-2 multi-temporal data in Banan District and Zhongxian County, typical hilly areas of Southwestern China. A pure pixel extraction algorithm was designed based on land-use vector data and a Google Earth Online image. Four convolutional neural network (CNN) algorithms (one-dimensional (Conv-1D), two-dimensional (Conv-2D) and three-dimensional (Conv-3D_1 and Conv-3D_2) convolutional neural networks) were developed and compared with four widely used classifiers (random forest (RF), extreme gradient boosting (XGBoost), support vector machine (SVM) and multilayer perceptron (MLP)). Recall, precision, overall accuracy (OA) and F1 score were applied to evaluate classification accuracy. The results showed that Conv-2D performed best in local classification experiments with OA of 93.14% and F1 score of 0.8552 in Banan District, OA of 92.53% and F1 score of 0.8399 in Zhongxian County. CNN-based models except Conv-1D provided more desirable performance than non-CNN classifiers. Besides, among the non-CNN classifiers, XGBoost received the best result with OA of 89.73% and F1 score of 0.7742 in Banan District, SVM received the best result with OA of 88.57% and F1 score of 0.7538 in Zhongxian County. In model transferability experiments, almost all CNN classifiers had low transferability. RF and XGBoost models have achieved acceptable F1 scores for transfer (RF = 0.6673 and 0.6469, XGBoost = 0.7171 and 0.6709, respectively).",Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology,yes,Sentinel-2,Agricultural crop (rice),Agriculture,Classification,no,88.38,75.44,78.27,72.8,,,,,,,,,,,
J,"Debella-Gilo, M; Gjertsen, AK",Mapping Seasonal Agricultural Land Use Types Using Deep Learning on Sentinel-2 Image Time Series,REMOTE SENSING,2021,multilayer perceptron; CNN; hyperparameter tuning; cereal; grass,"The size and location of agricultural fields that are in active use and the type of use during the growing season are among the vital information that is needed for the careful planning and forecasting of agricultural production at national and regional scales. In areas where such data are not readily available, an independent seasonal monitoring method is needed. Remote sensing is a widely used tool to map land use types, although there are some limitations that can partly be circumvented by using, among others, multiple observations, careful feature selection and appropriate analysis methods. Here, we used Sentinel-2 satellite image time series (SITS) over the land area of Norway to map three agricultural land use classes: cereal crops, fodder crops (grass) and unused areas. The Multilayer Perceptron (MLP) and two variants of the Convolutional Neural Network (CNN), are implemented on SITS data of four different temporal resolutions. These enabled us to compare twelve model-dataset combinations to identify the model-dataset combination that results in the most accurate predictions. The CNN is implemented in the spectral and temporal dimensions instead of the conventional spatial dimension. Rather than using existing deep learning architectures, an autotuning procedure is implemented so that the model hyperparameters are empirically optimized during the training. The results obtained on held-out test data show that up to 94 % overall accuracy and 90% Cohen's Kappa can be obtained when the 2D CNN is applied on the SITS data with a temporal resolution of 7 days. This is closely followed by the 1D CNN on the same dataset. However, the latter performs better than the former in predicting data outside the training set. It is further observed that cereal is predicted with the highest accuracy, followed by grass. Predicting the unused areas has been found to be difficult as there is no distinct surface condition that is common for all unused areas.",Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology,yes,Sentinel-2,Mapping Seasonal Agricultural Land Use Types,Vegetation,Classification,no,93,,,,,,,88,,,,,,,
J,"Tao, WC; Dong, Y; Su, W; Li, JY; Xuan, F; Huang, JX; Yang, JY; Li, XC; Zeng, YL; Li, BG",Mapping the Corn Residue-Covered Types Using Multi-Scale Feature Fusion and Supervised Learning Method by Chinese GF-2 PMS Image,FRONTIERS IN PLANT SCIENCE,2022,crop residue covering; multi-scale image features; machine learning; GF-2 PMS image; high spatial resolution remote sensing,"The management of crop residue covering is a vital part of conservation tillage, which protects black soil by reducing soil erosion and increasing soil organic carbon. Accurate and rapid classification of corn residue-covered types is significant for monitoring crop residue management. The remote sensing technology using high spatial resolution images is an effective means to classify the crop residue-covered areas quickly and objectively in the regional area. Unfortunately, the classification of crop residue-covered area is tricky because there is intra-object heterogeneity, as a two-edged sword of high resolution, and spectral confusion resulting from different straw mulching ways. Therefore, this study focuses on exploring the multi-scale feature fusion method and classification method to classify the corn residue-covered areas effectively and accurately using Chinese high-resolution GF-2 PMS images in the regional area. First, the multi-scale image features are built by compressing pixel domain details with the wavelet and principal component analysis (PCA), which has been verified to effectively alleviate intra-object heterogeneity of corn residue-covered areas on GF-2 PMS images. Second, the optimal image dataset (OID) is identified by comparing model accuracy based on the fusion of different features. Third, the 1D-CNN_CA method is proposed by combining one-dimensional convolutional neural networks (1D-CNN) and attention mechanisms, which are used to classify corn residue-covered areas based on the OID. Comparison of the naive Bayesian (NB), random forest (RF), support vector machine (SVM), and 1D-CNN methods indicate that the residue-covered areas can be classified effectively using the 1D-CNN-CA method with the highest accuracy (Kappa: 96.92% and overall accuracy (OA): 97.26%). Finally, the most appropriate machine learning model and the connected domain calibration method are combined to improve the visualization, which are further used to classify the corn residue-covered areas into three covering types. In addition, the study showed the superiority of multi-scale image features by comparing the contribution of the different image features in the classification of corn residue-covered areas.",Plant Sciences,yes,GaoFen-2,Corn residue types,Agriculture,Classification,no,97.15,,,,,,,96.85,,,,,,,
J,"Mukonza, SS; Chiang, JL",Micro-Climate Computed Machine and Deep Learning Models for Prediction of Surface Water Temperature Using Satellite Data in Mundan Water Reservoir,WATER,2022,water quality; water temperature; machine and deep learning; uncertainties; Landsat-8; Sentinel-3,"Water temperature is an important indicator of water quality for surface water resources because it impacts solubility of dissolved gases in water, affects metabolic rates of aquatic inhabitants, such as fish and harmful algal blooms (HABs), and determines the fate of water resident biogeochemical nutrients. Furthermore, global warming is causing a widespread rise in temperature levels in water sources on a global scale, threatening clean drinking water supplies. Therefore, it is key to increase the frequency of spatio-monitoring for surface water temperature (SWT). However, there is a lack of comprehensive SWT monitoring datasets because current methods for monitoring SWT are costly, time consuming, and not standardized. The research objective of this study was to estimate SWT using data from the Landsat-8 (L8) and Sentinel-3 (S3) satellites. To do this, we used machine learning techniques, such as Support Vector Regression (SVR), Gaussian Process Regression (GPR), simple neural network (ANN), and deep learning techniques (Long Short Term Memory, LSTM, and Convolutional Long Short Term Memory, 1D ConvLSTM). Using deep and machine learning techniques to regress satellite data to estimate SWT presents a number of challenges, including prediction uncertainty, over- or under-estimation of measured values, and significant variation in the final estimated data. The performance of the L8 ConvLSTM model was superior to all other methods (R-2 of 0.93 RMSE of 0.16 degrees C, and bias of 0.01 degrees C). The factors that had a significant effect on the model's accuracy performance were identified and quantified using a two-factor analysis of variance (ANOVA) analysis. The results demonstrate that the main effects and interaction of the type of machine/deep learning (ML/DL) model and the type of satellite have statistically significant effects on the performances of the different models. The test statistics are as follows: (satellite type main effect p *** <= 0.05, F-test = 15.4478), (type of ML/DL main effect p *** <= 0.05, F-test = 17.4607) and (interaction, satellite type x type of ML/DL p ** <= 0.05, F-test = 3.5325), respectively. The models were successfully deployed to enable satellite remote sensing monitoring of SWT for the reservoir, which will help to resolve the limitations of the conventional sampling and laboratory techniques.",Environmental Sciences & Ecology; Water Resources,yes,Landsat-8,Surface water temperature,Water,Regression,yes,,,,,,,,,,,,0.93,0.15,,Temperature (degree)
J,"Mukonza, SS; Chiang, JL",Micro-Climate Computed Machine and Deep Learning Models for Prediction of Surface Water Temperature Using Satellite Data in Mundan Water Reservoir,WATER,2022,water quality; water temperature; machine and deep learning; uncertainties; Landsat-8; Sentinel-3,"Water temperature is an important indicator of water quality for surface water resources because it impacts solubility of dissolved gases in water, affects metabolic rates of aquatic inhabitants, such as fish and harmful algal blooms (HABs), and determines the fate of water resident biogeochemical nutrients. Furthermore, global warming is causing a widespread rise in temperature levels in water sources on a global scale, threatening clean drinking water supplies. Therefore, it is key to increase the frequency of spatio-monitoring for surface water temperature (SWT). However, there is a lack of comprehensive SWT monitoring datasets because current methods for monitoring SWT are costly, time consuming, and not standardized. The research objective of this study was to estimate SWT using data from the Landsat-8 (L8) and Sentinel-3 (S3) satellites. To do this, we used machine learning techniques, such as Support Vector Regression (SVR), Gaussian Process Regression (GPR), simple neural network (ANN), and deep learning techniques (Long Short Term Memory, LSTM, and Convolutional Long Short Term Memory, 1D ConvLSTM). Using deep and machine learning techniques to regress satellite data to estimate SWT presents a number of challenges, including prediction uncertainty, over- or under-estimation of measured values, and significant variation in the final estimated data. The performance of the L8 ConvLSTM model was superior to all other methods (R-2 of 0.93 RMSE of 0.16 degrees C, and bias of 0.01 degrees C). The factors that had a significant effect on the model's accuracy performance were identified and quantified using a two-factor analysis of variance (ANOVA) analysis. The results demonstrate that the main effects and interaction of the type of machine/deep learning (ML/DL) model and the type of satellite have statistically significant effects on the performances of the different models. The test statistics are as follows: (satellite type main effect p *** <= 0.05, F-test = 15.4478), (type of ML/DL main effect p *** <= 0.05, F-test = 17.4607) and (interaction, satellite type x type of ML/DL p ** <= 0.05, F-test = 3.5325), respectively. The models were successfully deployed to enable satellite remote sensing monitoring of SWT for the reservoir, which will help to resolve the limitations of the conventional sampling and laboratory techniques.",Environmental Sciences & Ecology; Water Resources,yes,Sentinel-3,Surface water temperature,Water,Regression,yes,,,,,,,,,,,,0.91,0.2,,Temperature (degree)
J,"Vulova, S; Meier, F; Rocha, AD; Quanz, J; Nouri, H; Kleinschmit, B","Modeling urban evapotranspiration using remote sensing, flux footprints, and artificial intelligence",SCIENCE OF THE TOTAL ENVIRONMENT,2021,Urban water; Eddy covariance; Latent heat flux; 1D convolutional neural networks (CNN); Deep learning; Harmonized Landsat and Sentinel-2,"As climate change progresses, urban areas are increasingly affected by water scarcity and the urban heat island effect. Evapotranspiration (ET) is a crucial component of urban greening initiatives of cities worldwide aimed at mitigating these issues. However, ET estimation methods in urban areas have so far been limited. An expanding number of flux towers in urban environments provide the opportunity to directly measure ET by the eddy covariance method. In this study, we present a novel approach to model urban ET by combining flux footprint modeling, remote sensing and geographic information system (GIS) data, and deep learning and machine learning techniques. This approach facilitates spatio-temporal extrapolation of ET at a half-hourly resolution; we tested this approach with a two-year dataset from two flux towers in Berlin, Germany. The benefit of integrating remote sensing and GIS data into models was investigated by testing four predictor scenarios. Two algorithms (1D convolutional neural networks (CNNs) and random forest (RF)) were compared. The best-performing models were then used to model ET values for the year 2019. The inclusion of GIS data extracted using flux footprints enhanced the predictive accuracy of models, particularly when meteorological data was more limited. The bestperforming scenario (meteorological and GIS data) showed an RMSE of 0.0239 mm/h and R2 of 0.840 with RF and an RMSE of 0.0250 mm/h and a R2 of 0.824 with 1D CNN for the more vegetated site. The 2019 ET sum was substantially higher at the site surrounded by more urban greenery (366 mm) than at the inner-city site (223 mm), demonstrating the substantial influence of vegetation on the urban water cycle. The proposed method is highly promising for modeling ET in a heterogeneous urban environment and can support climate change mitigation initiatives of urban areas worldwide. (c) 2021 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license (http:// creativecommons.org/licenses/by/4.0/).",Environmental Sciences & Ecology,yes,Landsat-8,Modeling urban evapotranspiration,Urban,Regression,no,,,,,,,,,,,,0.824,25,16,Reference evapotranspiration (mm/h)
J,"Vulova, S; Meier, F; Rocha, AD; Quanz, J; Nouri, H; Kleinschmit, B","Modeling urban evapotranspiration using remote sensing, flux footprints, and artificial intelligence",SCIENCE OF THE TOTAL ENVIRONMENT,2021,Urban water; Eddy covariance; Latent heat flux; 1D convolutional neural networks (CNN); Deep learning; Harmonized Landsat and Sentinel-2,"As climate change progresses, urban areas are increasingly affected by water scarcity and the urban heat island effect. Evapotranspiration (ET) is a crucial component of urban greening initiatives of cities worldwide aimed at mitigating these issues. However, ET estimation methods in urban areas have so far been limited. An expanding number of flux towers in urban environments provide the opportunity to directly measure ET by the eddy covariance method. In this study, we present a novel approach to model urban ET by combining flux footprint modeling, remote sensing and geographic information system (GIS) data, and deep learning and machine learning techniques. This approach facilitates spatio-temporal extrapolation of ET at a half-hourly resolution; we tested this approach with a two-year dataset from two flux towers in Berlin, Germany. The benefit of integrating remote sensing and GIS data into models was investigated by testing four predictor scenarios. Two algorithms (1D convolutional neural networks (CNNs) and random forest (RF)) were compared. The best-performing models were then used to model ET values for the year 2019. The inclusion of GIS data extracted using flux footprints enhanced the predictive accuracy of models, particularly when meteorological data was more limited. The bestperforming scenario (meteorological and GIS data) showed an RMSE of 0.0239 mm/h and R2 of 0.840 with RF and an RMSE of 0.0250 mm/h and a R2 of 0.824 with 1D CNN for the more vegetated site. The 2019 ET sum was substantially higher at the site surrounded by more urban greenery (366 mm) than at the inner-city site (223 mm), demonstrating the substantial influence of vegetation on the urban water cycle. The proposed method is highly promising for modeling ET in a heterogeneous urban environment and can support climate change mitigation initiatives of urban areas worldwide. (c) 2021 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license (http:// creativecommons.org/licenses/by/4.0/).",Environmental Sciences & Ecology,yes,Sentinel-2,Modeling urban evapotranspiration,Urban,Regression,no,,,,,,,,,,,,0.824,25,16,Reference evapotranspiration (mm/h)
J,Afira N.; Wijayanto A.W.,"Mono-temporal and multi-temporal approaches for burnt area detection using Sentinel-2 satellite imagery (a case study of Rokan Hilir Regency, Indonesia)",Ecological Informatics,2022,Burnt area detection; Deep learning algorithms; Fire; Machine learning algorithms; Sentinel-2,"Accurate and up-to-date information about the burnt area is important in estimating environmental losses, prioritizing rehabilitation areas, and determining future planning strategies. The publicly available medium resolution optical Sentinel-2 satellite data provides a practical and effective solution for burnt area detection. In this study, we proposed two different approaches using mono-temporal and multi-temporal Sentinel-2 satellite imagery to detect burnt areas in Rokan Hilir Regency, Indonesia. The multi-temporal approaches utilized two different ensemble machine learning algorithms (Random Forest and XGBoost) and used six composite spectral indices of the differenced Normalized Burn Ratio (dNBR), differenced Normalized Burn Ratio 2 (dNBR2), differenced Normalized Difference Vegetation Index (dNDVI), differenced Soil Adjusted Vegetation Index (dSAVI), differenced Char Soil Index (dCSI), differenced Burnt area Index for Sentinel-2 (dBAIS2), and differenced Mid-infrared Burn Index (dMIRBI) as model inputs. The burnt areas are labeled by combining hotspots with confidence intervals above 95%, fire spots, and change detection methods. The XGBoost model achieved the best performance with an F1 score of 0.97 and an accuracy of 96%. Furthermore, we use the SHapley Additive exPlanations (SHAP) to quantify the contribution of each feature as well as its correlation with the target class. The dNBR, dMIRBI, and dNBR2 indices contribute the most to the XGBoost model. In comparison, this study also investigates and compares a mono-temporal approach with One-dimensional Convolutional Neural Network (CNN-1D) architecture and the performance obtained is slightly better than both machine learning models. Overall, both mono-temporal and multi-temporal approaches satisfactorily detect the burnt area. © 2022 Elsevier B.V.",,no,Sentinel-2,Burnt area detection,Geohazards,Classification,no,,,,,,,,,,,,,,,
J,"Bai, Maoyang; Peng, Peihao; Zhang, Shiqi; Wang, Xueman; Wang, Xiao; Wang, Juan; Pellikka, Petri",Mountain Forest Type Classification Based on One-Dimensional Convolutional Neural Network,FORESTS,2023,mountain forest; classification; one-dimensional convolutional neural network; Sentinel-1; Sentinel-2,"Convolutional neural networks (CNNs) have demonstrated their efficacy in remote sensing applications for mountain forest classification. However, two-dimensional convolutional neural networks (2D CNNs) require a significant manual involvement in the visual interpretation to obtain continuous polygon label data. To reduce the errors associated with manual visual interpretation and enhance classification efficiency, it is imperative to explore alternative approaches. In this research, we introduce a novel one-dimensional convolutional neural network (1D CNN) methodology that directly leverages field investigation data as labels for classifying mountain forest types based on multiple remote sensing data sources. The hyperparameters were optimised using an orthogonal table, and the model's performance was evaluated on Mount Emei of Sichuan Province. Comparative assessments with traditional classification methods, namely, a random forest (RF) and a support vector machine (SVM), revealed superior results obtained by the proposed 1D CNN. Forest type classification using the 1D CNN achieved an impressive overall accuracy (OA) of 97.41% and a kappa coefficient (Kappa) of 0.9673, outperforming the U-Net (OA: 94.45%, Kappa: 0.9239), RF (OA: 88.99%, Kappa: 0.8488), and SVM (OA: 88.79%, Kappa: 0.8476). Moreover, the 1D CNN model was retrained using limited field investigation data from Mount Wawu in Sichuan Province and successfully classified forest types in that region, thereby demonstrating its spatial-scale transferability with an OA of 90.86% and a Kappa of 0.8879. These findings underscore the effectiveness of the proposed 1D CNN in utilising multiple remote sensing data sources for accurate mountain forest type classification. In summary, the introduced 1D CNN presents a novel, efficient, and reliable method for mountain forest type classification, offering substantial contributions to the field.",Forestry,yes,Sentinel-2,Forest classification,Vegetation,Classification,no,97.41,,,,97.36,97.52,,96.73,,,,,,,
J,Sabir A.; Kumar A.,Optimized 1D-CNN model for medicinal Psyllium Husk crop mapping with temporal optical satellite data,Ecological Informatics,2022,1D-CNN (convolutional neural network); Deep learning; FERM (fuzzy error matrix); MSAVI2 (modified soil vegetation index); Psyllium Husk,"Deep Learning models are preferred for complex image analysis-based solutions to application-oriented problems. However, the architecture of such models largely influences the results which includes several hyperparameters that need to be tuned. This study aims at developing an optimized 1D-CNN model for medicinal Psyllium Husk crop mapping using open source temporal optical Sentinel-2A/2B satellite data. In this study, a sequential 1D-CNN model architecture was developed by optimizing hyperparameters which includes convolution layers, number of neurons, activation function, and batch size. Psyllium Husk crop fields were mapped in the Jalore district of Rajasthan using Sentinel 2A/ 2B (10 m) optical data. For spectral dimensionality reduction of the data, Modified Soil Adjusted Vegetation Index (MSAVI2) was used to maintain the data dimensionality since temporal data was utilized. The dataset was subsequently refined to include the target crop's specific phenological stages that distinguish it from other closely resembling species. The information corresponding to these specific crop stages was fed to the 1D-CNN model to carry out the classification. A range of training sample sizes were explored to determine the optimal number of training data points. As the output from the model, fractional images are obtained consisting of values proportional to the probability of a pixel lying in the target class. Accuracy assessment was carried out using fuzzy error matrix (FERM) by generating fractional output images from temporal optical PlanetScope data (3m) which was used as a reference. The best overall accuracy among the test cases came out to be 89.85% using conventional MSAVI2 with 1000 training samples. © 2022 Elsevier B.V.",,no,Sentinel-2,Psyllium Husk crop mapping,Agriculture,Classification,no,89.85,,,,,,,,,,,,,,
J,"Gunen, MA",Performance comparison of deep learning and machine learning methods in determining wetland water areas using EuroSAT dataset,ENVIRONMENTAL SCIENCE AND POLLUTION RESEARCH,2022,1D CNN; Remote sensing; Classification; Wetland; Sentinel-2,"Wetlands are critical to the ecology because they maintain biodiversity and provide home for a variety of species. Researching, mapping, and conservation of wetlands is a challenging and time-consuming process. Because they produce temporal and geographical information, remote sensing and photogrammetric approaches are useful tools for analyzing and managing wetlands. In this study, the water areas of five different wetlands obtained with Sentinel-2 images in Turkey were classified. Although obtaining large amounts of high-dimensional dataset labeled for various land types is costly, it is a significant advantage to use it after model training in a wide range of applications. In this paper, the EuroSAT dataset was used in the validation process. Proposed deep learning-based 1D convolutional neural networks (CNN) and traditional machine learning methods (i.e., support vector machine, linear discriminant analysis, K-nearest neighborhood, canonical correlation forests, and AdaBoost.M1) were compared quantitatively (i.e., accuracy, recall, precision, specificity, F-score, and image quality assessment metrics) and qualitatively. Finally, pairwise comparison was made with chi-square-based McNemar's test. There is a statistical difference between 1D CNN and machine learning method (except the support vector machine vs linear discriminant analysis in Test 1 area). CNN models outperform machine learning algorithms in terms of non-linear function approximation and the ability to extract and articulate data features. Since 1D CNNs can process data in a highly complex and unique feature space, they are very successful in segmenting strongly related and highly correlated discrete signals. It also has advantages over machine learning methods for water body extraction in that it can be integrated with sophisticated image pre-processing and standardization tools, is less susceptible to low-level random noise, and provides shift in variations and contrast-invariant image local transforms.",Environmental Sciences & Ecology,no,Sentinel-2,Determining wetland water areas,Water,Classification,no,,,,,,,,,,,,,,,
J,B. Yang; J. Guo; J. Liu; X. Ye,PPCE: A Practical Loss for Crop Mapping Using Phenological Prior,IEEE Geoscience and Remote Sensing Letters,2023,Crop mapping;crop phenology;deep learning;loss function;remote sensing,"Accurate and timely crop mapping using remote sensing technology is crucial for precision agriculture, yield estimation, and food security. Deep learning models trained with proper loss functions are widely used in crop mapping and have achieved promising results. However, most of the existing loss functions focus on loss optimization in a universal way, i.e., problems regarding sample imbalance, and neglect the uniqueness of crop mapping task, for which its target often shows phenological characteristics. Given this, this letter proposes a crop phenological prior cross entropy loss (PPCE) function, which focuses on guiding the training processing in the direction where crops can be better identified. It is practical and easy to use. The phenological prior is quantified using normalized difference yellow index and normalized difference vegetation index obtained in different growing periods. Under the supervision of PPCE, if a crop pixel is misclassified to other class, the prior knowledge will increase the contribution of its loss to the final loss and thus guide the network to extract more discriminative features for crop mapping. To demonstrate the performance of PPCE, five widely used loss functions combined with three typical deep learning models (LSTM, DNN, and 1D-CNN) are compared. Experimental results show better performance of PPCE than the existing loss functions with different deep learning models.",,yes,Sentinel-2,Crop mapping,Agriculture,Classification,no,97.12,92.41,,,,,,90.63,,,,,,,
J,B. Yang; J. Guo; J. Liu; X. Ye,PPCE: A Practical Loss for Crop Mapping Using Phenological Prior,IEEE Geoscience and Remote Sensing Letters,2023,Crop mapping;crop phenology;deep learning;loss function;remote sensing,"Accurate and timely crop mapping using remote sensing technology is crucial for precision agriculture, yield estimation, and food security. Deep learning models trained with proper loss functions are widely used in crop mapping and have achieved promising results. However, most of the existing loss functions focus on loss optimization in a universal way, i.e., problems regarding sample imbalance, and neglect the uniqueness of crop mapping task, for which its target often shows phenological characteristics. Given this, this letter proposes a crop phenological prior cross entropy loss (PPCE) function, which focuses on guiding the training processing in the direction where crops can be better identified. It is practical and easy to use. The phenological prior is quantified using normalized difference yellow index and normalized difference vegetation index obtained in different growing periods. Under the supervision of PPCE, if a crop pixel is misclassified to other class, the prior knowledge will increase the contribution of its loss to the final loss and thus guide the network to extract more discriminative features for crop mapping. To demonstrate the performance of PPCE, five widely used loss functions combined with three typical deep learning models (LSTM, DNN, and 1D-CNN) are compared. Experimental results show better performance of PPCE than the existing loss functions with different deep learning models.",,yes,HY-1C,Crop mapping,Agriculture,Classification,no,97.12,92.41,,,,,,90.63,,,,,,,
J,"Jeong, S; Ko, J; Yeom, JM",Predicting rice yield at pixel scale through synthetic use of crop and deep learning models with satellite data in South and North Korea,SCIENCE OF THE TOTAL ENVIRONMENT,2022,Crop yield prediction; Data driven model; Crop model; Remote sensing; Korean peninsula,"Prediction of rice yields at pixel scale rather than county scale can benefit crop management and scientific understanding because it is useful for monitoring how crop yields respond to various agricultural systems and environmental factors. In this study, we propose a methodology for the early prediction of rice yield at pixel scale combining a crop model and a deep learning model for different agricultural systems throughout South and North Korea. Initially, satellite-integrated crop models were applied to obtain a pixel-scale reference rice yield. Then, the pixel-scale reference rice yields were used as target labels in the deep learning model to leverage the advantages of crop models. Models of five different deep learning network architectures were employed to help determine the hybrid structure of long-short term memory (LSTM) and one-dimensional convolutional neural network (1D-CNN) layers by predicting the optimal model about two months ahead of harvest time. The suggested model showed good performance [R-2 = 0.859, Nash-Sutcliffe model efficiency = 0.858, root mean squared error = 0.605 Mg ha(-1)], with specific spatial patterns of rice yields for South and North Korea. Analysis of the relative importance of the input variables showed the water-related index and maximum temperature in North Korea and the vegetation indices and geographic variables in South Korea to be crucial for predicting rice yields. The proposed approach successfully predicted and diagnosed rice yield at the pixel scale for inaccessible locations where reliable ground measurements are not available, especially North Korea. (C) 2021 The Authors. Published by Elsevier B.V.",Environmental Sciences & Ecology,yes,MODIS,Predicting rice yield,Agriculture,Regression,yes,,,,,,,,,,,,0.86,0.61,,Rice yield (Mg/ha)
C,Li H.; Di L.; Zhang C.; Lin L.; Guo L.; Zhao H.,Prediction of Crop Planting Map Using One-dimensional Convolutional Neural Network and Decision Tree Algorithm,"2023 11th International Conference on Agro-Geoinformatics, Agro-Geoinformatics 2023",2023,CDL; crop map prediction; decision tree; one-dimensional CNN,"The crop type planting prediction map is an essential agro-geoinformation data source to explore and quantify agriculture cultivation distribution in the coming year, implying crop planting change tendency. This paper validates the feasibility of crop type prediction using a one-dimensional convolutional neural network (1D CNN) and decision tree algorithm. To construct the ID CNN model, we encode and stack the historical Cropland Data Layer (CDL) into a 3D time series location matrix as the training dataset. According to the validation for the 2021 crop planting map in Cass County of Iowa, the prediction result owns high overall accuracy (0.927) and kappa coefficient (0.857). The major crop types, corn and soybean, have high prediction producer accuracy (0.9 - 0.95) and user accuracy (0.91-0.94). The minor crop alfalfa has lower accuracy (0.55-0.73). This approach provides an option to predict major crop type's planting maps for the next year.  © 2023 IEEE.",,yes,"Landsat-8, Landsat-9, Sentinel-2",Crop planting map,Vegetation,Classification,yes,92.7,,,,,,,85.7,,,,,,,
C,Bahl G.; Lafarge F.,Scanner Neural Network for On-Board Segmentation of Satellite Images,International Geoscience and Remote Sensing Symposium (IGARSS),2022,Cloud Segmentation; ConvLSTM; Image Segmentation; On-board processing; Recurrent Convolutional Network; Satellite Imagery,"Traditional Convolutional Neural Networks (CNN) for semantic segmentation of images use 2D convolution operations. While the spatial inductive bias of 2D convolutions allow CNNs to build hierarchical feature representations, they require that the whole feature maps are kept in memory until the end of the inference. This is not ideal for memory and latency-critical applications such as real-time on-board satellite image segmentation. In this paper, we propose a new neural network architecture for semantic segmentation, 'ScannerNet', based on a Recurrent 1D Convolutional architecture. Our network performs a segmentation of the input image line-by-line, and thus reduces the memory footprint and output latency. These characteristics make it ideal for on-the-fly segmentation of images on-board satellites equipped with push broom sensors such as Landsat 8, or satellites with limited compute capabilities, such as Cubesats. We perform cloud segmentation experiments on embedded hardware and show that our method offers a good compromise between accuracy, memory usage and latency. © 2022 IEEE.",,yes,Landsat-8,Cloud segmentation,Others,Segmentation,yes,93.65,88.98,93.79,84.65,,,,,85.8,,,,,,
J,"Russwurm, M; Korner, M",Self-attention for raw optical Satellite Time Series Classification,ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING,2020,Self-attention; Transformer; Time series classification; Multitemporal Earth observation; Crop type mapping; Vegetation monitoring; Deep learning,"The amount of available Earth observation data has increased dramatically in recent years. Efficiently making use of the entire body of information is a current challenge in remote sensing; it demands lightweight problemagnostic models that do not require region- or problem-specific expert knowledge. End-to-end trained deep learning models can make use of raw sensory data by learning feature extraction and classification in one step, solely from data. Still, many methods proposed in remote sensing research require implicit feature extraction through data preprocessing or explicit design of features. In this work, we compare recent deep learning models on crop type classification on raw and preprocessed Sentinel 2 data. We concentrate on the common neural network architectures for time series, i.e., 1D-convolutions, recurrence, and the novel self-attention architecture. Our central findings are that data preprocessing still increased the overall classification performance for all models while the choice of model was less crucial. Self-attention and recurrent neural networks, by their architecture, outperformed convolutional neural networks on raw satellite time series. We explore this by a feature importance analysis based on gradient backpropagation that exploits the differentiable nature of deep learning models. Further, we qualitatively show how self-attention scores focus selectively on a few classification-relevant observations.",Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology,yes,Sentinel-2,Crop type classification,Agriculture,Classification,no,92,60,,,,,,71,,,,,,,
J,"Fang, J; He, GH; Zhu, ZJ; Attaher, BIM; Xue, J",Spatial-Spectral Decoupling Interaction Network for Multispectral Imagery Change Detection,IEEE GEOSCIENCE AND REMOTE SENSING LETTERS,2022,Mathematical models; Feature extraction; Geoscience and remote sensing; Neural networks; Fuses; Deep learning; Convolutional neural networks; Multispectral imagery change detection; spatial-spectral decoupling interaction network,"We present a spatial-spectral decoupling interaction network for multispectral imagery change detection, which can exploit the underlying information of the multispectral imagery adequately through simultaneously considering the discriminative attribute of each pixel and robust spatial structure of the corresponding patch. Specifically, a 1-D convolutional neural network (1D-CNN) is applied to the spectral vector of each pixel to extract its discriminative feature, while a 2D-CNN is applied to the patch centering on the corresponding pixel to explore the spatial structure information. In addition, an interaction mechanism is incorporated into the feature fusion module to enhance the spatial-spectral consistency.",Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science & Photographic Technology,yes,GaoFen-1,Multispectral imagery change detection,Others,Classification,yes,95.94,,,,,,,94.19,,,,,,,
J,"Fang, J; He, GH; Zhu, ZJ; Attaher, BIM; Xue, J",Spatial-Spectral Decoupling Interaction Network for Multispectral Imagery Change Detection,IEEE GEOSCIENCE AND REMOTE SENSING LETTERS,2022,Mathematical models; Feature extraction; Geoscience and remote sensing; Neural networks; Fuses; Deep learning; Convolutional neural networks; Multispectral imagery change detection; spatial-spectral decoupling interaction network,"We present a spatial-spectral decoupling interaction network for multispectral imagery change detection, which can exploit the underlying information of the multispectral imagery adequately through simultaneously considering the discriminative attribute of each pixel and robust spatial structure of the corresponding patch. Specifically, a 1-D convolutional neural network (1D-CNN) is applied to the spectral vector of each pixel to extract its discriminative feature, while a 2D-CNN is applied to the patch centering on the corresponding pixel to explore the spatial structure information. In addition, an interaction mechanism is incorporated into the feature fusion module to enhance the spatial-spectral consistency.",Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science & Photographic Technology,yes,Landsat-7,Multispectral imagery change detection,Others,Classification,yes,95.94,,,,,,,94.19,,,,,,,
C,Qadeer M.U.; Saeed S.; Taj M.; Muhammad A.,SPATIO-TEMPORAL CROP CLASSIFICATION ON VOLUMETRIC DATA,"Proceedings - International Conference on Image Processing, ICIP",2021,CNN; Crop Classification; Satellite data,"Large-area crop classification using multi-spectral imagery is a widely studied problem for several decades and is generally addressed using classical Random Forest classifier. Recently, deep convolutional neural networks (DCNN) have been proposed. However, these methods only achieved results comparable with Random Forest. In this work, we present a novel CNN based architecture for large-area crop classification. Our methodology combines both spatio-temporal analysis via 3D CNN as well as temporal analysis via 1D CNN. We evaluated the efficacy of our approach on Yolo and Imperial county benchmark datasets. Our combined strategy outperforms both classical as well as recent DCNN based methods in terms of classification accuracy by 2% while maintaining a minimum number of parameters and the lowest inference time. © 2021 IEEE",,yes,Sentinel-2,Crop classification,Agriculture,Classification,yes,90.23,90.08,,,,,,,,,,,,,
C,Qadeer M.U.; Saeed S.; Taj M.; Muhammad A.,SPATIO-TEMPORAL CROP CLASSIFICATION ON VOLUMETRIC DATA,"Proceedings - International Conference on Image Processing, ICIP",2021,CNN; Crop Classification; Satellite data,"Large-area crop classification using multi-spectral imagery is a widely studied problem for several decades and is generally addressed using classical Random Forest classifier. Recently, deep convolutional neural networks (DCNN) have been proposed. However, these methods only achieved results comparable with Random Forest. In this work, we present a novel CNN based architecture for large-area crop classification. Our methodology combines both spatio-temporal analysis via 3D CNN as well as temporal analysis via 1D CNN. We evaluated the efficacy of our approach on Yolo and Imperial county benchmark datasets. Our combined strategy outperforms both classical as well as recent DCNN based methods in terms of classification accuracy by 2% while maintaining a minimum number of parameters and the lowest inference time. © 2021 IEEE",,yes,Landsat-8,Crop classification,Agriculture,Classification,yes,90.23,90.08,,,,,,,,,,,,,
J,"Florath, J; Keller, S",Supervised Machine Learning Approaches on Multispectral Remote Sensing Data for a Combined Detection of Fire and Burned Area,REMOTE SENSING,2022,remote sensing; classification; burned area mapping; fire detection; deep learning; Sentinel-2 images; self-organizing maps; undersampling; imbalanced dataset; convolutional neural network,"Bushfires pose a severe risk, among others, to humans, wildlife, and infrastructures. Rapid detection of fires is crucial for fire-extinguishing activities and rescue missions. Besides, mapping burned areas also supports evacuation and accessibility to emergency facilities. In this study, we propose a generic approach for detecting fires and burned areas based on machine learning (ML) approaches and remote sensing data. While most studies investigated either the detection of fires or mapping burned areas, we addressed and evaluated, in particular, the combined detection on three selected case study regions. Multispectral Sentinel-2 images represent the input data for the supervised ML models. First, we generated the reference data for the three target classes, burned, unburned, and fire, since no reference data were available. Second, the three regional fire datasets were preprocessed and divided into training, validation, and test subsets according to a defined schema. Furthermore, an undersampling approach ensured the balancing of the datasets. Third, seven selected supervised classification approaches were used and evaluated, including tree-based models, a self-organizing map, an artificial neural network, and a one-dimensional convolutional neural network (1D-CNN). All selected ML approaches achieved satisfying classification results. Moreover, they performed a highly accurate fire detection, while separating burned and unburned areas was slightly more challenging. The 1D-CNN and extremely randomized tree were the best-performing models with an overall accuracy score of 98% on the test subsets. Even on an unknown test dataset, the 1D-CNN achieved high classification accuracies. This generalization is even more valuable for any use-case scenario, including the organization of fire-fighting activities or civil protection. The proposed combined detection could be extended and enhanced with crowdsourced data in further studies.",Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology,yes,Sentinel-2,Detection of Fire and Burned Area,Geohazards,Classification,no,97.6,96.4,96.5,,,,,92.9,,,,,,,
J,"Liao, CH; Wang, JF; Xie, QH; Al Baz, A; Huang, XD; Shang, JL; He, YJ",Synergistic Use of Multi-Temporal RADARSAT-2 and VEN mu S Data for Crop Classification Based on 1D Convolutional Neural Network,REMOTE SENSING,2020,crop classification; RADARSAT-2; VEN mu S; data fusion; deep learning; convolutional neural network,"Annual crop inventory information is important for many agriculture applications and government statistics. The synergistic use of multi-temporal polarimetric synthetic aperture radar (SAR) and available multispectral remote sensing data can reduce the temporal gaps and provide the spectral and polarimetric information of the crops, which is effective for crop classification in areas with frequent cloud interference. The main objectives of this study are to develop a deep learning model to map agricultural areas using multi-temporal full polarimetric SAR and multi-spectral remote sensing data, and to evaluate the influence of different input features on the performance of deep learning methods in crop classification. In this study, a one-dimensional convolutional neural network (Conv1D) was proposed and tested on multi-temporal RADARSAT-2 and VEN mu S data for crop classification. Compared with the Multi-Layer Perceptron (MLP), Recurrent Neural Network (RNN) and non-deep learning methods including XGBoost, Random Forest (RF), and Support Vector Machina (SVM), the Conv1D performed the best when the multi-temporal RADARSAT-2 data (Pauli decomposition or coherency matrix) and VEN mu S multispectral data were fused by the Minimum Noise Fraction (MNF) transformation. The Pauli decomposition and coherency matrix gave similar overall accuracy (OA) for Conv1D when fused with the VEN mu S data by the MNF transformation (OA = 96.65 +/- 1.03% and 96.72 +/- 0.77%). The MNF transformation improved the OA and F-score for most classes when Conv1D was used. The results reveal that the coherency matrix has a great potential in crop classification and the MNF transformation of multi-temporal RADARSAT-2 and VEN mu S data can enhance the performance of Conv1D.",Environmental Sciences & Ecology; Geology; Remote Sensing; Imaging Science & Photographic Technology,yes,VENµS,Cropland classification,Agriculture,Classification,no,96.65,,,,,,,95,,,,,,,
